<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://fjmartincampo.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://fjmartincampo.github.io/" rel="alternate" type="text/html" /><updated>2026-02-12T23:06:59+01:00</updated><id>https://fjmartincampo.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">The anatomy of a linear optimization problem</title><link href="https://fjmartincampo.github.io/blog/2026/theoreticalLO/" rel="alternate" type="text/html" title="The anatomy of a linear optimization problem" /><published>2026-02-01T01:05:00+01:00</published><updated>2026-02-01T01:05:00+01:00</updated><id>https://fjmartincampo.github.io/blog/2026/theoreticalLO</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/theoreticalLO/"><![CDATA[<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/theoryLO-480.webp 480w,/assets/img/theoryLO-800.webp 800w,/assets/img/theoryLO-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/theoryLO.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Linear optimization is much more than a tool for solving practical problems in production, logistics, or resource allocation: it is also an elegant mathematical object from a theoretical perspective.</p>

<p>Behind every optimal solution lie geometric and algebraic structures that allow us to understand:</p>

<ul>
  <li><strong>when</strong> optimal solutions exist,</li>
  <li><strong>how</strong> they are reached,</li>
  <li>and how the entire set of feasible solutions can be described.</li>
</ul>

<p>This post explores the fundamental concepts that support the theory of linear optimization:</p>

<ul>
  <li><strong>extreme points</strong>,</li>
  <li><strong>extreme directions</strong>,</li>
  <li>how to characterize them,</li>
  <li>and the <strong>representation theorem</strong> for the feasible region.</li>
</ul>

<p>The goal is to provide a clear conceptual framework that helps explain the <em>why</em> behind algorithms such as the Simplex method, beyond the purely mechanical computation of an optimal solution. In linear optimization, what is truly interesting is not only finding the optimum, but understanding the geometry behind it.</p>

<h2 id="notation-and-definitions">Notation and definitions</h2>

<p>A linear optimization problem in standard form can be written as:</p>

\[\begin{aligned}
\min \;\; &amp; z = \mathbf{c}^\intercal \mathbf{x} \\
\text{s.t.:}\;\; &amp; \mathbf{A}\mathbf{x} = \mathbf{b} \\
                &amp; \mathbf{x} \geqslant \mathbf{0}.
\end{aligned}\]

<p>The <strong>feasible set</strong> is defined as:</p>

\[\mathcal{S}=\{\mathbf{x} \in \mathbb{R}^n :
\mathbf{A}\mathbf{x} = \mathbf{b},\;
\mathbf{x}\geqslant \mathbf{0}\}.\]

<p>The technical coefficient matrix \(\mathbf{A}\in\mathbb{R}^{m\times n}\) can be interpreted as a collection of $n$ vectors in \(\mathbb{R}^m\):</p>

\[\mathbf{A} = (\mathbf{a}_1,\ldots,\mathbf{a}_n),\]

<p>where each column is:</p>

\[\mathbf{a}_j =
\begin{pmatrix}
a_{1j} \\
a_{2j} \\
\vdots \\
a_{mj}
\end{pmatrix},
\qquad j=1,\ldots,n.\]

<h3 id="bases-and-basic-solutions">Bases and basic solutions</h3>

<p>A common assumption in the theory is that the matrix \(\mathbf{A}\) has full row rank:</p>

\[\mathrm{rank}(\mathbf{A}) = m.\]

<p>In that case, there exists at least one square submatrix</p>

\[\mathbf{B}\in\mathbb{R}^{m\times m}, \qquad |\mathbf{B}| \neq 0,\]

<p>called a <strong>basis</strong>.</p>

<blockquote class="block-tip">
  <p>The $m$ column vectors forming the basis \(\mathbf{B}\) are linearly independent.</p>
</blockquote>

<p>Choosing a basis allows us to decompose the matrix as:</p>

\[\mathbf{A} = (\mathbf{B},\mathbf{N}),\]

<p>which induces a natural partition of the solution vector:</p>

\[\mathbf{x} =
\begin{pmatrix}
\mathbf{x}_{\mathbf{B}} \\
\mathbf{x}_{\mathbf{N}}
\end{pmatrix},\]

<p>where:</p>

<ul>
  <li>\(\mathbf{x}_{\mathbf{B}}\in\mathbb{R}^m\) are the <strong>basic variables</strong>,</li>
  <li>\(\mathbf{x}_{\mathbf{N}}\in\mathbb{R}^{n-m}\) are the <strong>nonbasic variables</strong>.</li>
</ul>

<h3 id="basic-solution">Basic solution</h3>

<blockquote class="block-tip">
  <p>A vector \(\mathbf{x}\in\mathbb{R}^n\) is called a <strong>basic solution</strong> if there exists a basis \(\mathbf{B}\subset\mathbf{A}\) such that the nonbasic variables are set to zero:</p>

\[\mathbf{x} = \begin{pmatrix} \mathbf{B}^{-1}\mathbf{b} \\ \mathbf{0} \end{pmatrix}.\]
</blockquote>

<h3 id="basic-feasible-solution">Basic feasible solution</h3>

<blockquote class="block-tip">
  <p>A basic solution is called <strong>feasible</strong> if it also satisfies the nonnegativity condition:</p>

\[\mathbf{B}^{-1}\mathbf{b}\geqslant 0.\]
</blockquote>

<p>Basic feasible solutions are especially important because they are directly related to the <strong>extreme points</strong> of the feasible region, as we will see next.</p>

<h2 id="convexity">Convexity</h2>

<p>One of the deepest aspects behind the theoretical analysis of linear optimization is <strong>convexity</strong>.</p>

<blockquote class="block-tip">
  <p>A nonempty set \(\mathcal{C} \subset \mathbb{R}^n\) is called <strong>convex</strong> if:</p>

\[\lambda \mathbf{x} + (1-\lambda)\mathbf{y} \in \mathcal{C} \qquad \forall \mathbf{x},\mathbf{y}\in\mathcal{C},\; \forall \lambda\in[0,1].\]
</blockquote>

<p>Geometrically, this means that for any two points in the set, the line segment joining them remains entirely inside the set.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/conveng-480.webp 480w,/assets/img/conveng-800.webp 800w,/assets/img/conveng-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/conveng.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Convex set" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/noconveng-480.webp 480w,/assets/img/noconveng-800.webp 800w,/assets/img/noconveng-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/noconveng.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Nonconvex set" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<blockquote class="block-tip">
  <p>The feasible set of a linear optimization problem,</p>

\[\mathcal{S}=\{\mathbf{x}\in\mathbb{R}^n:\mathbf{A}\mathbf{x}=\mathbf{b},\;\mathbf{x}\geqslant 0\},\]

  <p>is a convex set.</p>
</blockquote>

<h2 id="extreme-points">Extreme points</h2>

<p>Although \(\mathcal{S}\) contains infinitely many points, its structure is determined by a much smaller collection of special elements: the <strong>extreme points</strong>, which correspond to the “vertices” of the feasible polytope.</p>

<blockquote class="block-tip">
  <p>If an optimal solution exists, then it can be found at an extreme point.</p>
</blockquote>

<p>For this reason, it is essential to understand what extreme points are and how they can be characterized.</p>

<blockquote class="block-tip">
  <p>Given a convex set \(\mathcal{C}\subset\mathbb{R}^n\), a point \(\mathbf{x}\in\mathcal{C}\) is called an <strong>extreme point</strong> if:</p>

\[\mathbf{x}=\lambda\mathbf{y}+(1-\lambda)\mathbf{z}, \;0&lt;\lambda&lt;1, \;\mathbf{y},\mathbf{z}\in\mathcal{C} \Rightarrow\]

\[\mathbf{x}=\mathbf{y}=\mathbf{z}.\]
</blockquote>

<p>In other words, an extreme point cannot be expressed as a convex combination of two distinct points in the set.</p>

<blockquote class="block-tip">
  <p><em>Characterization of extreme points</em></p>

  <p>Let \(\mathcal{S}=\{\mathbf{x}\in\mathbb{R}^n:\mathbf{A}\mathbf{x}=\mathbf{b},\;\mathbf{x}\geqslant 0\},\) where \(\mathbf{A}\in\mathbb{R}^{m\times n}\) and \(\mathrm{rank}(\mathbf{A})=m\). Then:</p>

  <p>\(\bar{\mathbf{x}}\) is an extreme point of
\(\mathcal{S}\) if and only if</p>

  <p>\(\exists\,\mathbf{B}\subset\mathbf{A}\) such that
\(|\mathbf{B}|\neq 0, \;\mathbf{B}^{-1}\mathbf{b}\geqslant 0.\)</p>

  <p>In that case:</p>

\[\bar{\mathbf{x}}= \begin{pmatrix} \mathbf{B}^{-1}\mathbf{b}\\ \mathbf{0} \end{pmatrix}.\]
</blockquote>

<p>The number of extreme points is bounded by:</p>

\[\binom{n}{m}.\]

<p>If $\mathcal{S} \neq \emptyset$, then at least one extreme point exists.</p>

<h2 id="extreme-directions">Extreme directions</h2>

<p>In problems with <strong>unbounded</strong> feasible regions, we encounter <strong>extreme directions</strong>, which describe how the feasible set can extend infinitely.</p>

<blockquote class="block-tip">
  <p>A nonzero vector \(\mathbf{d}\neq 0\) is a <strong>direction</strong> of a convex set \(\mathcal{C}\) if:</p>

\[\forall\mathbf{x}\in\mathcal{C},\; \forall\mu\geqslant 0 \Rightarrow \mathbf{x}+\mu\mathbf{d}\in\mathcal{C}.\]

  <p>Two directions \(\mathbf{d}^1\) and \(\mathbf{d}^2\) are equivalent if \(\mathbf{d}^1=\alpha\mathbf{d}^2,\; \alpha&gt;0.\)</p>
</blockquote>

<p>In linear optimization,</p>

<blockquote class="block-tip">
  <p>Given the feasible set $\mathcal{S}={\mathbf{x} \in \mathbb{R}^n : \mathbf{A}\mathbf{x} = \mathbf{b}, \mathbf{x} \geqslant \mathbf{0}}$, we have:</p>

  <p>\(\mathbf{d}\) is a direction of
\(\mathcal{S}\) if and only if
\(\mathbf{d} \geqslant 0,\; \mathbf{d}\neq 0,\; \mathbf{A}\mathbf{d}=0.\)</p>
</blockquote>

<blockquote class="block-tip">
  <p>Given a convex set $\mathcal{C}$, a direction $\mathbf{d}$ is called an <strong>extreme direction</strong> if whenever:</p>

\[\mathbf{d} = \mu_1 \mathbf{d}^1 + \mu_2 \mathbf{d}^2,\]

  <p>with $\mu_1,\mu_2&gt;0$ and $\mathbf{d}^1,\mathbf{d}^2$ directions of $\mathcal{C}$, then:</p>

\[\mathbf{d} \simeq \mathbf{d}^1 \simeq \mathbf{d}^2.\]
</blockquote>

<p>Extreme directions can also be characterized.</p>

<blockquote class="block-tip">
  <p><em>Characterization of extreme directions</em></p>

  <p>Let $\mathcal{S}={\mathbf{x} \in \mathbb{R}^n : \mathbf{A}\mathbf{x} = \mathbf{b}, \mathbf{x} \geqslant \mathbf{0}}$, where $\mathbf{A}$ is an $m\times n$ matrix with $\mathrm{rank}(\mathbf{A})=m$. Then:</p>

  <p>$\mathbf{d}$ is an extreme direction of $\mathcal{S}$ if and only if there exists a basis $\mathbf{B}\subset\mathbf{A}$ with $|\mathbf{B}|\neq 0$
such that $\mathbf{A}=(\mathbf{B},\mathbf{N}),$ and there exists a column $\mathbf{a}_j\in\mathbf{N}$ satisfying $\mathbf{B}^{-1}\mathbf{a}_j\leqslant 0,$
so that $\mathbf{d}=\alpha\mathbf{d}^0$ with $\alpha&gt;0$ and:</p>

\[\mathbf{d}^0=\begin{pmatrix}-\mathbf{B}^{-1} \mathbf{a}_j \\ \mathbf{e}_j\end{pmatrix},\]

  <p>where $\mathbf{e}_j$ is the vector with all components zero except the $j$-th, which equals 1.</p>
</blockquote>

<p>The number of extreme directions is bounded by:</p>

\[\binom{n}{m+1}.\]

<h2 id="representation-theorem">Representation Theorem</h2>

<p>The representation theorem is a consequence of several classical results in convex geometry thanks to the works of <a href="https://es.wikipedia.org/wiki/Hermann_Minkowski">Minkowski</a>, <a href="https://en.wikipedia.org/wiki/Constantin_Carathéodory">Carathéodory</a>, <a href="https://en.wikipedia.org/wiki/Ernst_Steinitz">Steinitz</a>, <a href="https://en.wikipedia.org/wiki/Hermann_Weyl">Weyl</a> and <a href="https://en.wikipedia.org/wiki/Theodore_Motzkin">Motzkin</a> (<a class="citation" href="#Minkowski1897">(Minkowski, 1897)</a>, <a class="citation" href="#Caratheodory1907">(Carathéodory, 1907)</a>, <a class="citation" href="#Steinitz1916">(Steinitz, 1916)</a>, <a class="citation" href="#Weyl1935">(Weyl, 1935)</a>, <a class="citation" href="#Motzkin1936">(Motzkin, 1936)</a>), established even before the birth of linear optimization as a discipline.</p>

<blockquote class="block-tip">
  <p><em>Representation Theorem</em></p>

  <p>Let $\mathcal{S}={\mathbf{x} \in \mathbb{R}^n : \mathbf{A}\mathbf{x} = \mathbf{b}, \mathbf{x} \geqslant \mathbf{0}}$, where $\mathbf{A}$ is an $m\times n$ matrix with $\mathrm{rank}(\mathbf{A})=m$.<br />
Let ${\mathbf{x}^1,\ldots,\mathbf{x}^k}$ be the set of extreme points of $\mathcal{S}$ and ${\mathbf{d}^1,\ldots,\mathbf{d}^l}$ its extreme directions. Then:</p>

\[\mathbf{x} \in \mathcal{S} \Leftrightarrow \wedge \begin{cases} \exists (\lambda_1,\ldots,\lambda_k) &amp; \lambda_i \geqslant 0,\; \sum_{i=1}^k \lambda_i = 1 \\ \exists (\mu_1,\ldots,\mu_l) &amp; \mu_j \geqslant 0 \end{cases}\]

  <p>such that:</p>

\[\mathbf{x} = \sum_{i=1}^k \lambda_i \mathbf{x}^i + \sum_{j=1}^l \mu_j \mathbf{d}^j.\]
</blockquote>

<p>This theorem shows that every feasible solution can be expressed entirely in terms of extreme points and extreme directions. To do so, one must identify these sets using the characterization results presented above.</p>

<h3 id="examples">Examples</h3>

<p>Consider the feasible region (independent of the objective function) of a linear optimization problem, written in standard form by adding slack variables:</p>

\[\begin{aligned}
-x_1 + x_2 &amp; \leqslant 2 \\
 x_1 - 2x_2 &amp; \leqslant 2 \\
 x_1, x_2 &amp; \geqslant 0
\end{aligned} \qquad 
\begin{aligned}
-x_1 + x_2 + x_3^h &amp; = 2 \\
x_1 - 2x_2 + x_4^h &amp; = 2 \\
x_1, x_2, x_3^h, x_4^h &amp; \geqslant 0
\end{aligned}\]

<p>This problem has three extreme points:</p>

\[\mathbf{x}_1 = \begin{pmatrix}0 \\ 0 \\ 2 \\ 2\end{pmatrix} \qquad
\mathbf{x}_2 = \begin{pmatrix}2 \\ 0 \\ 4 \\ 0\end{pmatrix} \qquad
\mathbf{x}_3 = \begin{pmatrix}0 \\ 2 \\ 0 \\ 6\end{pmatrix}\]

<p>and two extreme directions:</p>

\[\mathbf{d}_1 = \begin{pmatrix}1 \\ 1 \\ 0 \\ 1\end{pmatrix} \qquad
\mathbf{d}_2 = \begin{pmatrix}2 \\ 1 \\ 1 \\ 0\end{pmatrix}\]

<p>represented in the following figure in $\mathbb{R}^2$:</p>

<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
      



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/teorrep-480.webp 480w,/assets/img/teorrep-800.webp 800w,/assets/img/teorrep-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/teorrep.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Representation theorem example" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Using the representation theorem, the set $\mathcal{S}$ can be written as:</p>

\[\begin{aligned}
\mathcal{S}
=\Biggl\{
&amp;\lambda_1
\begin{pmatrix}
0\\0\\2\\2
\end{pmatrix}
+\lambda_2
\begin{pmatrix}
2\\0\\4\\0
\end{pmatrix}
+\lambda_3
\begin{pmatrix}
0\\2\\0\\6
\end{pmatrix} 
+\mu_1
\begin{pmatrix}
1\\1\\0\\1
\end{pmatrix}
+\mu_2
\begin{pmatrix}
2\\1\\1\\0
\end{pmatrix}
:\; \\[0.4em]
&amp; \lambda_1+\lambda_2+\lambda_3=1, 
\lambda_1,\lambda_2,\lambda_3\geqslant 0,
\qquad
\mu_1,\mu_2\geqslant 0
\Biggr\}.
\end{aligned}\]

<h3 id="consequences-of-the-representation-theorem">Consequences of the representation theorem</h3>

<p>The representation theorem allows us to classify the different types of solutions of a minimization linear optimization problem.</p>

<ul>
  <li>
    <p>The problem is <strong>unbounded</strong> if there exists an extreme direction $\mathbf{d}^j$ such that $\mathbf{c}^\intercal \mathbf{d}^j &lt; 0$.</p>
  </li>
  <li>
    <p>The problem has an <strong>optimal solution</strong> if all extreme directions satisfy $\mathbf{c}^\intercal \mathbf{d}^j \geqslant 0$, or if no extreme directions exist, and the optimum is attained at an extreme point.</p>
  </li>
</ul>

<h2 id="resolution-procedure-and-combinatorics">Resolution procedure and combinatorics</h2>

<p>Using the same feasible region, we now analyze different cost vectors, which lead to different objective functions and therefore different types of solutions.</p>

<ul>
  <li>$\mathbf{c}^\intercal = (2,-3,0,0)$</li>
</ul>

\[\mathbf{c}^\intercal \mathbf{d}^1 = (2,-3,0,0)\begin{pmatrix}1 \\ 1 \\ 0 \\ 1\end{pmatrix} = -1 &lt; 0,\]

<p>so the problem is unbounded.</p>

<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
      



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/teorrep1-480.webp 480w,/assets/img/teorrep1-800.webp 800w,/assets/img/teorrep1-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/teorrep1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Unbounded optimal solution" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<ul>
  <li>$\mathbf{c}^\intercal = (4,-3,0,0)$</li>
</ul>

<p>Since \(\mathbf{c}^\intercal \mathbf{d}^1 \geqslant 0\) and \(\mathbf{c}^\intercal \mathbf{d}^2 \geqslant 0,\)</p>

<p>the problem has an optimal solution, attained at the vertex with minimum objective value, namely $\mathbf{x}^3$ (where \(\mathbf{c}^\intercal \mathbf{x}^3 = -6\)).</p>

<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
      



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/teorrep2-480.webp 480w,/assets/img/teorrep2-800.webp 800w,/assets/img/teorrep2-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/teorrep2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Unique optimal solution" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<ul>
  <li>$\mathbf{c}^\intercal = (0,1,0,0)$</li>
</ul>

<p>Again, \(\mathbf{c}^\intercal \mathbf{d}^1 \geqslant 0\) and \(\mathbf{c}^\intercal \mathbf{d}^2 \geqslant 0,\)</p>

<p>so the problem has an optimal solution. In this case, two vertices attain the same minimum value: $\mathbf{x}^1$ and $\mathbf{x}^2$, with</p>

\[\mathbf{c}^\intercal \mathbf{x}^1 = \mathbf{c}^\intercal \mathbf{x}^2 = 0.\]

<p>The set of optimal solutions is:</p>

\[\left\{\lambda\begin{pmatrix}0 \\ 0 \\ 2 \\ 2\end{pmatrix}
+ (1-\lambda)\begin{pmatrix}2 \\ 0 \\ 4 \\ 0\end{pmatrix},
\;\; \lambda \in [0,1]\right\}.\]

<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
      



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/teorrep3-480.webp 480w,/assets/img/teorrep3-800.webp 800w,/assets/img/teorrep3-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/teorrep3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple optimal solutions in a bounded region" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<ul>
  <li>$\mathbf{c}^\intercal = (1,-1,0,0)$</li>
</ul>

<p>Since \(\mathbf{c}^\intercal \mathbf{d}^1 \geqslant 0\) and \(\mathbf{c}^\intercal \mathbf{d}^2 \geqslant 0,\)</p>

<p>the problem has an optimal solution. Evaluating the vertices, the minimum is attained at $\mathbf{x}^3$, where \(\mathbf{c}^\intercal \mathbf{x}^3 = -2.\)</p>

<p>The set of optimal solutions is:</p>

\[\left\{\begin{pmatrix}0 \\ 2 \\ 0 \\ 6\end{pmatrix}
+ \mu\begin{pmatrix}1 \\ 1 \\ 0 \\ 1\end{pmatrix},
\;\; \mu \geqslant 0 \right\}.\]

<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
      



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/teorrep4-480.webp 480w,/assets/img/teorrep4-800.webp 800w,/assets/img/teorrep4-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/teorrep4.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple optimal solutions in an unbounded region" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<h2 id="combinatorics">Combinatorics</h2>

<p>The combinatorial growth of all possible bases becomes extremely fast. Even for moderate dimensions, such as $n=40$ and $m=20$, we obtain:</p>

\[\binom{40}{20}=137,846,528,820.\]

<p>Although enumerating all extreme points and extreme directions is not practical for large-scale problems due to this combinatorial explosion, the theoretical analysis provides the essential foundations: it reveals the geometric structure of the feasible region, characterizes the possible types of solutions, and ultimately motivates the development of efficient algorithms such as the Simplex method, which exploits precisely these properties.</p>]]></content><author><name></name></author><category term="algorithms" /><category term="OR" /><category term="LinearOptimization" /><category term="concepts" /><category term="resolution" /><summary type="html"><![CDATA[Geometric characterization of linear optimization problems, extreme points, extreme directions, and the representation theorem]]></summary></entry><entry><title type="html">El Algoritmo Símplex, el Motor de la Optimización Matemática</title><link href="https://fjmartincampo.github.io/blog/2026/simplex/" rel="alternate" type="text/html" title="El Algoritmo Símplex, el Motor de la Optimización Matemática" /><published>2026-02-01T01:05:00+01:00</published><updated>2026-02-01T01:05:00+01:00</updated><id>https://fjmartincampo.github.io/blog/2026/simplex</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/simplex/"><![CDATA[<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/simplex-480.webp 480w,/assets/img/simplex-800.webp 800w,/assets/img/simplex-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/simplex.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Desde su introducción por <strong><a href="https://en.wikipedia.org/wiki/George_Dantzig">George B. Dantzig</a> en 1947</strong>, el Algoritmo Símplex ha sido calificado como uno de los avances más influyentes en el cálculo científico y la toma de decisiones estratégicas. Su importancia radica en su capacidad para resolver problemas de <strong>optimización lineal</strong>, permitiendo encontrar de forma eficiente el valor óptimo (máximo o mínimo) de una función sujeta a múltiples restricciones de recursos.</p>

<p>A diferencia de otros métodos, el Símplex navega de forma inteligente por los vértices de la región factible, garantizando que, si existe una solución óptima, esta será alcanzada en un número finito de pasos.</p>

<h2 id="1-el-sistema-explícito-la-base-del-algoritmo">1. El Sistema Explícito: La Base del Algoritmo</h2>

<p>Para que el algoritmo pueda evaluar si una solución es óptima o cómo mejorarla, es necesario transformar el problema original en un <strong>sistema explícito</strong> asociado a una base $\mathbf{B}$. Partimos de la forma estándar: 
\(\min z = \mathbf{c}^\intercal x\) sujeto a 
\(\mathbf{Ax} = \mathbf{b}\), 
\(\mathbf{x} \geqslant \mathbf{0}\)</p>

<p>Dividiendo las variables en básicas ($x_B$) y no básicas ($x_N$), y multiplicando por la inversa de la base ($B^{-1}$), obtenemos las ecuaciones clave [5, 6]:</p>

<ul>
  <li>
    <p><strong>Ecuaciones de las variables básicas:</strong> 
\(x_B = \bar{x}_B - \sum_{j \in J} y_j x_j\) 
Donde $\bar{x}_B = B^{-1}b$ es la solución básica actual y $y_j = B^{-1}a_j$ [4].</p>
  </li>
  <li>
    <p><strong>Ecuación de costes (Función Objetivo):</strong>
\(z = \bar{z} - \sum_{j \in J} (z_j - c_j)x_j\)
Aquí, $\bar{z}$ representa el valor actual de la función objetivo y la magnitud $(c_j - z_j)$ nos indica cuánto aumenta (o disminuye) la función por cada unidad que incrementamos la variable no básica $x_j$ [7, 8].</p>
  </li>
</ul>

<h2 id="2-los-tres-teoremas-del-símplex">2. Los Tres Teoremas del Símplex</h2>

<p>El comportamiento y la lógica de parada del algoritmo se fundamentan en estos tres teoremas esenciales (planteados para un problema de <strong>minimización</strong>):</p>

<ol>
  <li><strong>Primer Teorema (Optimalidad):</strong> Una solución básica factible es óptima si para toda variable no básica se cumple que $z_j - c_j \leq 0$ [9, 10].</li>
  <li><strong>Segundo Teorema (Solución No Acotada):</strong> Si existe una variable no básica $k$ tal que $z_k - c_k &gt; 0$ y todos los elementos de su vector asociado son no positivos ($y_k \leq 0$), entonces el problema tiene una solución óptima no acotada [11, 12].</li>
  <li><strong>Tercer Teorema (Mejora de la Solución):</strong> Si para una solución básica factible existe un índice $k$ tal que $z_k - c_k &gt; 0$ y al menos un componente de $y_k$ es positivo ($y_k \not\leq 0$), existe una nueva base $B’$ que proporciona una solución factible con un valor de la función objetivo menor o igual al actual [13, 14].</li>
</ol>

<h2 id="3-ejemplos-numéricos">3. Ejemplos Numéricos</h2>

<p>Para ilustrar estos teoremas, veamos casos extraídos de situaciones reales de cálculo:</p>

<h3 id="caso-a-solución-óptima-alcanzada">Caso A: Solución Óptima Alcanzada</h3>
<p>En un problema de minimización con base $B_1$, obtenemos los siguientes valores [11, 15]:</p>
<ul>
  <li>$\bar{z} = 6$</li>
  <li>$z_4 - c_4 = 0$</li>
  <li>$z_5 - c_5 = -6$
Al ser todos los $z_j - c_j \leq 0$, el <strong>Primer Teorema</strong> garantiza que la solución $(\bar{x}_1=1, \bar{x}_2=1, \bar{x}_3=1, \bar{x}_4=0, \bar{x}_5=0)$ es <strong>óptima</strong> [9, 11].</li>
</ul>

<h3 id="caso-b-problema-no-acotado">Caso B: Problema No Acotado</h3>
<p>Consideremos un sistema donde identificamos una variable $x_2$ tal que [16]:</p>
<ul>
  <li>$z_2 - c_2 = 2$ (Indica que el valor puede seguir bajando).</li>
  <li>$y_2 = \begin{pmatrix} 0 \ -1 \end{pmatrix}$ (No hay restricciones que detengan el crecimiento de $x_2$).
Bajo el <strong>Segundo Teorema</strong>, concluimos que el valor de la función objetivo puede decrecer indefinidamente [16, 17].</li>
</ul>

<h3 id="caso-c-mejora-mediante-cambio-de-base">Caso C: Mejora mediante Cambio de Base</h3>
<p>Si partimos de una base $B_2$ donde $z_2 - c_2 = 6 &gt; 0$ y el vector $y_2$ tiene componentes positivos como $\begin{pmatrix} 1 \ 0 \ 1 \end{pmatrix}$ [18, 19]:
El <strong>Tercer Teorema</strong> nos indica que debemos realizar un “pivoteo”. Al introducir $x_2$ en la base y sacar la variable correspondiente (regla del cociente mínimo), logramos una nueva solución factible que mejora (o mantiene) el valor de la función objetivo [13, 20, 21].</p>]]></content><author><name></name></author><category term="algorithms" /><category term="OR" /><category term="LinearOptimization" /><category term="simplex" /><category term="resolution" /><summary type="html"><![CDATA[El método clásico que convirtió la optimización en una herramienta computacional efectiva.]]></summary></entry><entry><title type="html">Exploring linear optimization through graphical methods</title><link href="https://fjmartincampo.github.io/blog/2026/graphical/" rel="alternate" type="text/html" title="Exploring linear optimization through graphical methods" /><published>2026-01-25T01:05:00+01:00</published><updated>2026-01-25T01:05:00+01:00</updated><id>https://fjmartincampo.github.io/blog/2026/graphical</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/graphical/"><![CDATA[<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/rulegraphic-480.webp 480w,/assets/img/rulegraphic-800.webp 800w,/assets/img/rulegraphic-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/rulegraphic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Linear optimization is a powerful tool for making decisions, from scheduling production to allocating resources efficiently.</p>

<p>Even though real-world problems often involve many variables, the <strong>two-variable case</strong> is especially useful for learning. Graphical methods let you <strong>see the problem</strong>: what solutions are possible, where constraints lie, and why some solutions are better than others.</p>

<p>The graphical approach represents each constraint as a region on a plane and highlights the area where <strong>all constraints overlap</strong>. Suddenly, an abstract problem becomes a tangible geometric figure, making the idea of an optimal solution much easier to understand.</p>

<h2 id="setting-up-the-problem">Setting up the problem</h2>

<p>A linear optimization problem with two variables can be written as:</p>

<ul>
  <li>
    <p>Objective function: \(\max\; z = c_1 x_1 + c_2 x_2\) or \(\min\; z = c_1 x_1 + c_2 x_2\).</p>
  </li>
  <li>
    <p>Subject to linear constraints: \(a_{i1} x_1 + a_{i2} x_2 \leqslant b_i, \; \forall i = 1, \dots, m\).</p>
  </li>
  <li>
    <p>Decision variables: \(x_1\) and \(x_2\) (often assumed non-negative, \(\geqslant 0\)).</p>
  </li>
</ul>

<p>The goal is to find values of $x_1$ and $x_2$ that optimize $z$ while respecting all constraints.</p>

<h2 id="visualizing-constraints-and-the-feasible-region">Visualizing constraints and the feasible region</h2>

<p>Intuitively, the feasible region contains <strong>all decisions that are allowed</strong> by the problem.</p>

<p>Each linear constraint defines a half-plane in $\mathbb{R}^2$. To draw a constraint:</p>
<ol>
  <li>Draw the line corresponding to the equality.</li>
  <li>Determine which side satisfies the inequality.</li>
  <li>Shade the feasible half-plane.</li>
</ol>

<p>Non-negativity constraints keep the solution in the first quadrant.</p>

<p>The <strong>feasible region</strong> is simply the intersection of all these half-planes. Some key geometric facts are:</p>

<ul>
  <li>The feasible region is convex.</li>
  <li>It can be bounded (a polygon) or unbounded.</li>
  <li>All feasible solutions lie within or on the boundary.</li>
</ul>

<p>If no point satisfies all constraints, the problem is <strong>infeasible</strong>.</p>

<h2 id="the-objective-function-and-optimality">The objective function and optimality</h2>

<p>The objective function can be pictured as a family of parallel lines:</p>

\[z := c_1 x_1 + c_2 x_2 = k\]

<p>Each $k$ gives a different line. Maximizing (or minimizing) the objective function consists of moving this line in the direction of improvement defined by the objective function coefficients while it still intersects the feasible region.</p>

<p>Graphically, the optimum is found where the line <strong>last touches</strong> the feasible region, usually at a <strong>vertex</strong> or <strong>extreme point</strong>. Sometimes, multiple optimal solutions lie along an edge (a segment in a bounded region or a ray in an unbounded region).</p>

<p>This leads to a key linear optimization result:</p>

<blockquote class="block-tip">
  <p>If an optimal solution exists, at least one occurs at a vertex of the feasible region.</p>
</blockquote>

<p>Several situations may arise:</p>

<blockquote class="block-tip">
  <ul>
    <li><strong>Unique optimum</strong>: the objective function, at its optimum, touches the feasible region at a single vertex.</li>
    <li><strong>Multiple optimal solutions</strong>:
      <ul>
        <li><strong>Bounded region</strong>: the objective function, at its optimum, coincides with a segment on the boundary of the feasible region, i.e., a side of the polygon.</li>
        <li><strong>Unbounded region</strong>: the objective function, at its optimum, coincides with a ray on the boundary of the feasible region (the feasible region must be unbounded).</li>
      </ul>
    </li>
    <li><strong>Unbounded optimal solution</strong>: the objective function can improve indefinitely.</li>
    <li><strong>Infeasible problem</strong>: there is no solution, i.e., the feasible region is empty.</li>
  </ul>
</blockquote>

<p>In practice, feasible regions are usually bounded, because decision variables represent finite resources.</p>

<h2 id="illustrative-examples">Illustrative Examples</h2>

<p>We will explore examples showing all the scenarios dynamically with animations.</p>

<h3 id="unique-optimal-solution">Unique Optimal Solution</h3>

<p>Consider the following linear optimization problem:</p>

\[\begin{aligned}
\max\;\;&amp; z = 6x_1 + 3x_2 \\
\text{s. t.:}\;\;&amp; 2x_1 + 4x_2 \leqslant 8 \\
&amp; -x_1 + 4x_2 \leqslant 4 \\
&amp; x_1 - x_2 \leqslant 2 \\
&amp; x_1, x_2 \geqslant 0
\end{aligned}\]

<p>The animation shows the feasible region forming and the objective line moving until the optimum at a vertex:</p>
<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/Unique-480.webp 480w,/assets/img/Unique-800.webp 800w,/assets/img/Unique-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/Unique.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Unique optimal solution" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>The optimal solution is at vertex $D=(8/3,2/3)^\intercal$, giving an objective function value, after substituting $x_1$ and $x_2$, of $z^* = 18$.</p>

<h3 id="multiple-optima-in-a-bounded-region">Multiple Optima in a Bounded Region</h3>

<p>Consider:</p>

\[\begin{aligned}
\max\;\;&amp; z = x_1 + x_2 \\
\text{s. t.:}\;\;&amp; x_1 + x_2 \leqslant 8 \\
&amp; -4x_1 + 4x_2 \leqslant 8 \\
&amp; 2x_1 - x_2 \leqslant 6 \\
&amp; x_1, x_2 \geqslant 0
\end{aligned}\]

<p>The animation shows how, in this case, the objective function line coincides with an entire edge of the feasible region.</p>
<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/MultipleBounded-480.webp 480w,/assets/img/MultipleBounded-800.webp 800w,/assets/img/MultipleBounded-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/MultipleBounded.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple optimal solutions in bounded region" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Vertices $C=(3,5)^\intercal$ and $D=(14/3,10/3)^\intercal$, as well as all points along the segment between them, are optimal. Therefore, the optimal solutions are the convex linear combination between points $C$ and $D$, given by:</p>

\[\lambda \left(\begin{array}{c} 3 \\ 5\end{array}\right) + (1-\lambda) \left(\begin{array}{c} 14/3 \\ 10/3\end{array} \right), \quad \lambda \in [0,1]\]

<p>with an objective function value $z^*=8$.</p>

<h3 id="multiple-optima-in-an-unbounded-region">Multiple Optima in an Unbounded Region</h3>

<p>Consider:</p>

\[\begin{aligned}
\min\;\;&amp; z = x_1 \\
\text{s. t.:}\;\;&amp; x_1 - x_2 \leqslant 2 \\
&amp; 2x_1 + 2x_2 \geqslant 1 \\
&amp; x_1, x_2 \geqslant 0
\end{aligned}\]

<p>The animation shows how, in this case as well, the objective function line coincides with an entire edge of the feasible region.</p>
<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/MultipleUnbounded-480.webp 480w,/assets/img/MultipleUnbounded-800.webp 800w,/assets/img/MultipleUnbounded-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/MultipleUnbounded.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple optimal solutions in unbounded region" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Vertex $C=(0,1/2)^\intercal$ is an optimal solution, together with the points on the ray starting from $C$ along the positive direction of the y-axis. The optimal solutions are given by:</p>

\[\left(\begin{array}{c} 0 \\ 1/2\end{array}\right) + \mu \left(\begin{array}{c} 0 \\ 1 \end{array}\right), \quad \mu \geqslant 0\]

<p>where the vertex and the vector defining the direction of the ray (or <strong>extreme direction</strong>) are taken into account. All these points yield the same objective function value, $z^*=0$.</p>

<h3 id="unbounded-optimal-solution">Unbounded Optimal Solution</h3>

<p>Consider:</p>

\[\begin{aligned}
\max\;\;&amp; z = x_1 + 2x_2 \\
\text{s. t.:}\;\;&amp; x_1 + 2x_2 \geqslant 2 \\
&amp; -2x_1 + x_2 \leqslant 4 \\
&amp; x_1, x_2 \geqslant 0
\end{aligned}\]

<p>The animation shows how, in this case, the objective function line can move indefinitely, improving the solution without limit.</p>
<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/Unbounded-480.webp 480w,/assets/img/Unbounded-800.webp 800w,/assets/img/Unbounded-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/Unbounded.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Unbounded optimal solution" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Following the direction of improvement of the objective function does not reach any vertex, allowing the objective function to increase as much as desired. In this case, the optimal objective value is $z^* = \infty$.</p>

<h3 id="infeasible-problem">Infeasible Problem</h3>

<p>Consider:</p>

\[\begin{aligned}
\min\;\;&amp; z = x_1 + x_2 \\
\text{s. t.:}\;\;&amp; 2x_1 + x_2 \leqslant 5 \\
&amp; x_1 - x_2 \geqslant 4 \\
&amp; x_1, x_2 \geqslant 0
\end{aligned}\]

<p>The animation shows that, in this case, there is no intersection of the first quadrant with the two constraints.</p>
<div class="row">  
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/Infeasible-480.webp 480w,/assets/img/Infeasible-800.webp 800w,/assets/img/Infeasible-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/Infeasible.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Infeasible problem" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>The feasible region is empty, therefore, the problem is infeasible, and no solution exists that satisfies all constraints.</p>

<p>In all studied cases, the behavior of the solution depends exclusively on the geometry of the feasible region and the direction of the objective function. It is important to ensure that the objective function line moves in the correct direction according to the optimization criterion (maximization or minimization) and not to confuse <strong>unbounded region</strong> with <strong>unbounded optimal solution</strong>.</p>

<blockquote class="block-tip">
  <p>In two dimensions, solving a linear optimization problem consists of:</p>

  <ol>
    <li>Constructing the feasible region.</li>
    <li>Identifying its vertices and extreme directions.</li>
    <li>Moving the objective line in the correct direction.</li>
    <li>Analyzing the point or set of points where the optimum is reached (if it exists).</li>
  </ol>
</blockquote>

<h2 id="limitations-of-the-graphical-method">Limitations of the Graphical Method</h2>

<p>The graphical approach is limited to problems with two or three decision variables. For higher-dimensional problems, algorithmic methods such as the Simplex Algorithm or Interior Point Methods are required.</p>

<p>Nevertheless, the geometric intuition acquired in two dimensions remains valid and serves as a foundation for understanding more advanced techniques. We can observe that:</p>

<ul>
  <li>Convexity: The solution set of the problem is convex.</li>
  <li>Vertices or extreme points: They are the points potentially candidates to be the optimal solution.</li>
  <li>Extreme directions: Occur in problems with unbounded feasible regions, allowing to define the set of optimal solutions (in case of multiple optima) or the improvement direction when obtaining an unbounded optimal solution.</li>
  <li>Types of solution: Different conclusions can be drawn when solving the problem.</li>
</ul>

<p>The graphical method provides a clear and intuitive way to understand linear optimization. Understanding this method is an important first step toward more general and powerful optimization tools. These geometric ideas are what allow reasoning to be generalized to methods like the Simplex, where it is no longer possible to <em>draw</em> the problem, but reasoning about vertices and extreme directions is still valid.</p>]]></content><author><name></name></author><category term="algorithms" /><category term="OR" /><category term="LinearOptimization" /><category term="graphical" /><category term="resolution" /><summary type="html"><![CDATA[Discover how graphical methods provide intuition for linear optimization before moving on to algorithmic techniques like the Simplex.]]></summary></entry><entry><title type="html">Linear optimization, mathematics for better decision-making</title><link href="https://fjmartincampo.github.io/blog/2026/linearoptimization/" rel="alternate" type="text/html" title="Linear optimization, mathematics for better decision-making" /><published>2026-01-18T10:00:00+01:00</published><updated>2026-01-18T10:00:00+01:00</updated><id>https://fjmartincampo.github.io/blog/2026/linearoptimization</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/linearoptimization/"><![CDATA[<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/poliedro-480.webp 480w,/assets/img/poliedro-800.webp 800w,/assets/img/poliedro-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/poliedro.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Linear optimization, originally known as linear programming, is the branch of mathematics devoted to solving complex decision-making problems when resources are limited. Through simple yet powerful mathematical models, it enables the planning, distribution, and allocation of resources in an efficient way. This methodology has a broad impact on sectors such as logistics, finance, and strategic planning.</p>

<p>Linear programming should not be confused with computer programming. In this context, <em>programming</em> refers to planning a set of actions to solve a problem optimally, not to writing code. To avoid such confusion, in 2010 the <em>Mathematical Programming Society</em> decided to change its name to the <a href="https://www.mathopt.org"><em>Mathematical Optimization Society</em></a>, better reflecting its focus on mathematical optimization and efficient decision-making.</p>

<h2 id="historical-development-of-linear-optimization">Historical development of Linear Optimization</h2>

<p>The history of linear optimization begins long before it was formalized as a discipline. As early as 1826, <a href="https://en.wikipedia.org/wiki/Joseph_Fourier">Joseph Fourier</a> developed a mathematical method for eliminating variables in systems of linear inequalities, now known as the <em>Fourier Elimination Method</em> <a class="citation" href="#Fourier1826">(Fourier, 1826)</a>. His approach was purely theoretical, aimed at studying problems in algebra and mathematical analysis. Almost a century later, in 1936, <a href="https://en.wikipedia.org/wiki/Theodore_Motzkin">Théodore Motzkin</a> extended and formalized this method for more complex systems of inequalities, establishing what is now called the <em>Fourier–Motzkin Elimination Method</em> <a class="citation" href="#Motzkin1936">(Motzkin, 1936)</a>. The fundamental difference between the two lies in their objectives: Fourier sought to solve general mathematical problems, while Motzkin laid the foundations for broader applications, moving closer to the field of optimization.</p>

<p>In 1939, <a href="https://en.wikipedia.org/wiki/Theodore_Motzkin">Leonid Kantorovich</a> published a book, in Russian, <a class="citation" href="#Kantorovich1939">(Kantorovich, 1939)</a> proposing linear optimization formulations and a simple, though inefficient, method for solving resource allocation problems. This book was translated into English in 1960 <a class="citation" href="#Kantorovich1960">(Kantorovich, 1960)</a>. Shortly afterward, in 1941, <a href="https://en.wikipedia.org/wiki/Frank_Lauren_Hitchcock">Frank Hitchcock</a> applied linear optimization to the transportation problem <a class="citation" href="#Hitchcock1941">(Hitchcock, 1941)</a>, demonstrating how these techniques could be used in concrete logistical situations.</p>

<p>The major breakthrough came in 1947, when <a href="https://en.wikipedia.org/wiki/George_Dantzig">George Dantzig</a> developed the <strong>Simplex Algorithm</strong> <a class="citation" href="#Dantzig1951">(Dantzig, 1951)</a>, an efficient procedure capable of solving linear optimization problems in practice. This algorithm is considered a cornerstone of operations research and one of the most important advances of the twentieth century <a class="citation" href="#Cipra2000">(Cipra, 2000)</a>. In 1951, Tjalling Koopmans used linear optimization to formulate complex economic problems, highlighting its usefulness for large-scale resource planning <a class="citation" href="#Koopmans1951">(Koopmans, 1951)</a>. Decades later, in 1984, Narendra Karmarkar introduced the <strong>Interior Point Method</strong> <a class="citation" href="#Karmarkar1984">(Karmarkar, 1984)</a>, showing that linear optimization problems could be solved in polynomial time and did not belong to the class $\mathcal{NP}$, as previously believed. The class $\mathcal{NP}$ includes problems whose solutions may be very difficult to find, whereas $\mathcal{P}$ groups problems that can be solved efficiently.</p>

<p>For their contributions to the theory of optimal resource allocation, Koopmans and Kantorovich received the <strong>Nobel Prize in Economics in 1975</strong>. However, Koopmans believed that Dantzig also deserved the prize, since the Simplex Algorithm was fundamental for the practical application of linear optimization and for bringing these ideas into the real world.</p>

<p>Having seen how the methods that shaped linear optimization were developed, it is now useful to understand the basic concepts that allow these problems to be formulated and solved.</p>

<h2 id="basic-concepts">Basic concepts</h2>

<p>In linear optimization, the core idea is to make smart decisions in an environment with limited resources. To do so, three key elements are used: <strong>decision variables</strong>, which represent what we can control or adjust; the <strong>objective function</strong>, which indicates what we want to achieve, such as maximizing profits or minimizing costs; and the <strong>set of constraints</strong>, which represent the system’s limitations, such as budget, time, or available materials. Together, these elements define a set of feasible solutions, and the task of linear optimization is to find the best option within that set. Although the theory may sound abstract, these concepts are applied every day, from deciding how many products to manufacture to planning delivery routes or allocating resources in a hospital, among many other examples.</p>

<p>In linear optimization, although problems may appear in many different forms, they are usually transformed into a <strong>standard formulation</strong> or a <strong>canonical formulation</strong>:</p>

<ul>
  <li><strong>Standard formulation</strong>
    <ul>
      <li>All constraints are expressed as <strong>equalities</strong>.</li>
      <li>All variables are <strong>non-negative</strong>.</li>
      <li>This formulation allows algorithms to work uniformly with any problem.</li>
    </ul>
  </li>
</ul>

\[\begin{aligned}
\min\;\;\;           &amp; z = \mathbf{c}^\intercal \mathbf{x} \\
\text{s.t.:}\;\;\;   &amp; \mathbf{A}\mathbf{x} = \mathbf{b} \\
                     &amp; \mathbf{x} \geqslant \mathbf{0}
\end{aligned}\]

<ul>
  <li><strong>Canonical formulation</strong>
    <ul>
      <li>Focuses on <strong>maximization</strong> problems (or equivalently <strong>minimization</strong>).</li>
      <li>Constraints are of the type <strong>≤</strong> (or equivalently <strong>≥</strong>).</li>
      <li>Variables are <strong>non-negative</strong>.</li>
      <li>This is the most common way to present problems before applying optimization methods.</li>
    </ul>
  </li>
</ul>

\[\begin{aligned}
\min\;\;\;           &amp; z = \mathbf{c}^\intercal \mathbf{x} \\
\text{s.t.:}\;\;\;   &amp; \mathbf{A}\mathbf{x} \geqslant \mathbf{b} \\
                     &amp; \mathbf{x} \geqslant \mathbf{0}
\end{aligned} \qquad
\begin{aligned}
\max\;\;\;           &amp; z = \mathbf{c}^\intercal \mathbf{x} \\
\text{s.t.:}\;\;\;   &amp; \mathbf{A}\mathbf{x} \leqslant \mathbf{b} \\
                     &amp; \mathbf{x} \geqslant \mathbf{0}
\end{aligned}\]

<blockquote class="block-tip">
  <p>Although these formulations may appear abstract, they are essential for turning real-world problems into <strong>mathematical models that can be solved by algorithms</strong>.</p>
</blockquote>

<h2 id="illustrative-example">Illustrative example</h2>

<p>Suppose a company produces two products, A and B, with the following data:</p>

<ul>
  <li>Each unit of A generates a profit of 40€, and each unit of B generates 30€.</li>
  <li>There are 100 units of raw material available and 80 hours of production time.</li>
  <li>Producing one unit of A requires 2 units of raw material and 1 hour of time.</li>
  <li>Producing one unit of B requires 1 unit of raw material and 2 hours of time.</li>
</ul>

<p>We define the <strong>decision variables</strong>:</p>
<ul>
  <li>$x_A$ = number of units of A to produce.</li>
  <li>$x_B$ = number of units of B to produce.</li>
</ul>

<p>The <strong>objective function</strong>, which we want to <strong>maximize</strong>, is the total profit:</p>

\[\max\; z = 40x_A + 30x_B\]

<p>The <strong>constraints</strong> of the system are:</p>

<ul>
  <li>Available raw materials: \(2x_A + 1x_B \leqslant 100\)</li>
  <li>Available time: \(1x_A + 2x_B \leqslant 80\)</li>
  <li>Non-negative productions: \(x_A \geqslant 0, \quad x_B \geqslant 0\)</li>
</ul>

<p>Once defined in this way, the problem can be solved using the Simplex method or interior point methods, yielding the optimal combination of products A and B.</p>

<h2 id="practical-applications-and-usefulness">Practical applications and usefulness</h2>

<p>Linear optimization is not just a collection of formulas and algorithms; its true value lies in how it is applied to improve real-world decisions. Today, this tool is used in <em>logistics</em> to plan transportation routes and manage inventories; in <em>industrial production</em> to allocate resources efficiently and maximize profits; in <em>finance</em> to design investment portfolios or optimal budgets; and in <em>strategic planning</em>, from hospitals managing beds and staff to companies optimizing supply chains. As George Dantzig, one of the founding figures of linear optimization, pointed out, linear optimization makes it possible to formalize objectives and make optimal decisions even in complex systems:</p>

<blockquote class="block-tip">
  <p>“<em>Linear programming is viewed as a revolutionary development giving man the ability to state general objectives and to find, by means of the simplex method, optimal policy decisions for a broad class of practical decision problems of great complexity. In the real world, planning tends to be ad hoc because of the many special-interest groups with their multiple objectives</em>” <a class="citation" href="#Dantzig1983">(Dantzig, 1983)</a>.</p>
</blockquote>

<p>From Fourier to modern methods, linear optimization shows how mathematical theory can lead to efficient and tangible decisions in the real world, across fields such as logistics, finance, and industrial production.</p>]]></content><author><name></name></author><category term="history" /><category term="OR" /><category term="LinearOptimization" /><category term="definitions" /><summary type="html"><![CDATA[A journey through the origins of linear optimization, its basic concepts, and its key role in efficient decision-making]]></summary></entry><entry><title type="html">The science behind decision-making in a complex world - operations research</title><link href="https://fjmartincampo.github.io/blog/2026/historyOR/" rel="alternate" type="text/html" title="The science behind decision-making in a complex world - operations research" /><published>2026-01-11T16:00:00+01:00</published><updated>2026-01-11T16:00:00+01:00</updated><id>https://fjmartincampo.github.io/blog/2026/historyOR</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/historyOR/"><![CDATA[<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/puzzle-480.webp 480w,/assets/img/puzzle-800.webp 800w,/assets/img/puzzle-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/puzzle.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Every day we make decisions with limited resources: time, money, energy, personnel, or production capacity, among others. Some decisions are simple, but others affect large and complex systems in which different elements are tightly interconnected, making decision-making significantly more difficult. In such cases, relying solely on intuition is usually not enough.</p>

<p>Operations research emerged precisely to address this type of situation. Its goal is to help make better decisions based on data, using scientific models and methods, with optimization as a central pillar.</p>

<h2 id="historical-evolution">Historical evolution</h2>

<p>The origins of operations research can be traced back to World War II. However, although the discipline was not formally established until then, its development can be divided into three stages: before the war, during the war, and after the war.</p>

<h3 id="mathematical-foundations-of-operations-research">Mathematical foundations of operations research</h3>

<p>The need to optimize resources is not a modern concern. Long before operations research existed as a discipline, similar problems were already being considered:</p>
<ul>
  <li>Finding the shortest and safest routes for trade.</li>
  <li>Designing strong structures using the minimum amount of material.</li>
  <li>Maximizing profits or minimizing costs in economic activities.</li>
</ul>

<p>From a mathematical perspective, scholars such as Euler, Lagrange, and Gauss developed fundamental tools for solving optimization problems. However, these advances were mainly focused on theoretical problems and had not yet evolved into a systematic methodology applied to the management of real organizations and systems.</p>

<h3 id="the-birth-of-operations-research">The birth of operations research</h3>

<p>Operations research emerged as a discipline during World War II. In the United Kingdom, teams composed of scientists from different fields began working together to solve very concrete problems:</p>
<ul>
  <li>How to allocate military resources more effectively.</li>
  <li>How to use radar more efficiently.</li>
  <li>How to organize maritime convoys to reduce losses.</li>
</ul>

<p>For the first time, optimization was applied in a structured way to large-scale real-world decisions. The results were so successful that, after the war, this approach was quickly transferred to the civilian sector.</p>

<h3 id="from-military-applications-to-everyday-life-expansion-into-the-civilian-world">From military applications to everyday life: expansion into the civilian world</h3>

<p>From the 1950s onward, operations research began to be used in companies, public administrations, and industrial settings. Its applications expanded to areas such as:</p>
<ul>
  <li>Production planning.</li>
  <li>Inventory management.</li>
  <li>Workforce scheduling.</li>
  <li>Design of transportation and distribution networks.</li>
</ul>

<p>During this period, many of the classical tools of the discipline were developed, always driven by a fundamental question: what is the best way to do things given a set of conditions?</p>

<p>For a more detailed overview of the history of operations research, see <a class="citation" href="#historyOR">(McCloskey, 1987)</a>.</p>

<h2 id="what-is-operations-research">What is operations research?</h2>

<p>With this context, it becomes easier to understand what we mean by operations research. Below are some of the most widely recognized formal definitions:</p>

<blockquote class="block-tip">
  <p><strong>Operational Research Society (United Kingdom)</strong></p>

  <p><em>First definition</em>: Operations research is the application of scientific methods to complex problems arising in the direction and management of large systems of men, machines, materials and money.</p>

  <p><em>Modern definition</em>: Operational research is a scientific approach to the solution of problems in the management of complex systems that enables decision makers to make better decisions.</p>
</blockquote>

<blockquote class="block-tip">
  <p><strong>Churchman, Ackoff, and Arnoff</strong> <a class="citation" href="#Churchman1957">(Churchman et al., 1957)</a></p>

  <p>Operations Research is the application of scientific methods, techniques, and tools to problems involving the operations of a system so as to provide those in control of the system with optimum solutions to the problems.</p>
</blockquote>

<blockquote class="block-tip">
  <p><strong>Hillier and Lieberman</strong> <a class="citation" href="#Hillier1967">(Hillier &amp; Lieberman, 1967)</a></p>

  <p>Operations research is concerned with scientifically deciding how to best design and operate man–machine systems, usually under conditions requiring the allocation of scarce resources.</p>
</blockquote>

<blockquote class="block-tip">
  <p><strong>INFORMS</strong></p>

  <p>Operations research and analytics is the discipline of using advanced analytical methods to help make better decisions.</p>
</blockquote>

<p>In simple terms, operations research consists of understanding a real-world problem, representing it through an abstract model, and using that model to make better decisions, i.e., is the science of better decision-making.</p>

<h2 id="the-need-to-organize-knowledge-scientific-societies">The need to organize knowledge: scientific societies</h2>

<p>As operations research grew and was applied in more domains, a clear need emerged: to organize the people working in this field, share knowledge, and give visibility to the discipline. This led to the creation of scientific societies.</p>

<p>These organizations make it possible to:</p>
<ul>
  <li>Connect researchers, practitioners, and students.</li>
  <li>Share theoretical advances and practical applications.</li>
  <li>Organize conferences and scientific meetings.</li>
  <li>Promote education and outreach.</li>
</ul>

<p>Thanks to these societies, operations research has become a well-established discipline at an international level.</p>

<h3 id="major-operations-research-societies">Major operations research societies</h3>

<ul>
  <li><a href="https://www.theorsociety.com">ORS</a> (Operational Research Society) – United Kingdom, 1948.</li>
  <li><a href="https://www.informs.org">INFORMS</a> – United States, 1952.</li>
  <li><a href="https://www.ifors.org">IFORS</a> (International Federation of Operational Research Societies) – 1959.</li>
  <li><a href="https://www.euro-online.org">EURO</a> (Association of European Operational Research Societies) – 1975.</li>
  <li><a href="https://sites.google.com/view/asociacin-latino-ibero-america/">ALIO</a> (Latin-Iberoamerican Association of Operations Research) – 1980.</li>
</ul>

<h3 id="operations-research-in-spain-seio">Operations research in Spain: SEIO</h3>

<p>In Spain, the discipline is represented by <a href="https://www.seio.es/home">SEIO</a> (Spanish Society of Statistics and Operations Research), which brings together researchers and professionals from both statistics and operations research.</p>

<p>Its main objectives are:</p>
<ul>
  <li>To promote the scientific and applied development of both disciplines.</li>
  <li>To organize conferences and training activities.</li>
  <li>To foster collaboration between academia, industry, and the public sector.</li>
  <li>To disseminate the role of operations research in society.</li>
</ul>

<h2 id="operations-research-today">Operations research today</h2>

<p>Today, operations research plays a role in many decisions that affect our daily lives, even if we are not always aware of it. The discipline has evolved alongside computing, data availability, and the growing complexity of modern systems. It is used, for example, in:</p>

<ul>
  <li>Commercial logistics:
    <ul>
      <li>Facility location.</li>
      <li>Warehouse management.</li>
      <li>Production planning.</li>
      <li>Workforce scheduling.</li>
      <li>Distribution and transportation networks.</li>
    </ul>
  </li>
  <li>Humanitarian logistics:
    <ul>
      <li>Prevention: risk analysis, scenario simulation, optimization of early warning systems.</li>
      <li>Mitigation: management of strategic inventories and resource allocation.</li>
      <li>Preparedness: evacuation route planning, personnel organization, and drills.</li>
      <li>Response: distribution of humanitarian aid, allocation of critical resources, and planning under uncertainty.</li>
      <li>Recovery: reconstruction planning, management of multiple projects, and long-term inventory control.</li>
    </ul>
  </li>
  <li>Military logistics:
    <ul>
      <li>Optimal allocation of resources.</li>
      <li>Planning of convoy routes and transportation.</li>
      <li>Management of critical inventories.</li>
      <li>Scheduling of maintenance and equipment repair.</li>
      <li>Optimization of operations under uncertainty.</li>
    </ul>
  </li>
</ul>

<p>Operations research is no longer focused solely on finding mathematically “optimal” solutions. Its current goal is to provide useful, robust, and implementable decisions, even when information is incomplete or problems are too large to be solved exactly.</p>

<p>In an increasingly interconnected world with limited resources, operations research remains an essential tool for understanding complexity, evaluating alternatives, and making better decisions.</p>]]></content><author><name></name></author><category term="history" /><category term="OR" /><category term="definitions" /><category term="societies" /><summary type="html"><![CDATA[A journey through the history, scientific societies and impact of operations research]]></summary></entry><entry><title type="html">How to model the n-queens problem using linear programming</title><link href="https://fjmartincampo.github.io/blog/2025/queens/" rel="alternate" type="text/html" title="How to model the n-queens problem using linear programming" /><published>2025-12-14T16:00:00+01:00</published><updated>2025-12-14T16:00:00+01:00</updated><id>https://fjmartincampo.github.io/blog/2025/queens</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2025/queens/"><![CDATA[<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/queens-480.webp 480w,/assets/img/queens-800.webp 800w,/assets/img/queens-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/queens.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Chess is one of the oldest and most celebrated board games in history, with origins dating back over a thousand years. Traditionally played on an $8 \times 8$ board, chess involves strategy, tactics, and deep thinking, as each piece moves according to specific rules. Beyond the game itself, the chessboard and its pieces have inspired a variety of logic puzzles and mathematical challenges.</p>

<p>One of the most famous of these is the <strong>eight queens problem</strong>, which asks how to place eight queens on a standard chessboard so that no two queens threaten each other—meaning that no two queens share the same row, column, or diagonal. This puzzle has fascinated mathematicians and enthusiasts alike, as it combines combinatorial reasoning with spatial visualization.</p>

<p>The problem can also be generalized to place the maximum number of queens on a board of different dimensions, $m \times n$, creating a family of logic challenges with increasing complexity. For example, the board shown below represents one possible solution to the eight queens problem. On a standard chessboard, there are a total of <strong>92 distinct solutions</strong>, making this a rich and engaging puzzle for anyone interested in logic, mathematics, and chess.</p>

<div class="row justify-content-center">
  <div class="col-auto">
      



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/queens.svg" sizes="95vw" />
      
    
    <img src="/assets/img/queens.svg" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>To model Sudoku as a <strong>binary linear optimization problem</strong>, we need to first define all the components of the model.</p>

<blockquote class="block-tip">
  <p><em>Sets of indices</em></p>
  <ul>
    <li>\(\mathcal{R}\): Rows of the board.</li>
    <li>\(\mathcal{C}\): Columns of the board.</li>
  </ul>
</blockquote>

<blockquote class="block-tip">
  <p><em>Parameters</em></p>
  <ul>
    <li>There are no additional parameters, since the board is initially considered empty.</li>
  </ul>
</blockquote>

<blockquote class="block-tip">
  <p><em>Decision variables</em></p>
  <ul>
    <li>\(x_{rc} = 1\) if there is a queen located at coordinate $(r,c)$ of the board, and 0 otherwise.</li>
  </ul>
</blockquote>

<p>The objective is to place the maximum number of queens on the chessboard.</p>

<blockquote class="block-tip">
  <p><em>Objective function</em></p>

\[\max z = \displaystyle \sum_{r \in \mathcal{R}} \displaystyle \sum_{c \in \mathcal{C}} x_{rc}\]
</blockquote>

<p>Below, we enumerate the <strong>constraints</strong> that ensure no queens attack each other.</p>

<blockquote class="block-tip">
  <p><em>Each row must contain one queen at most:</em></p>

\[\displaystyle \sum_{r \in \mathcal{R}} x_{rc} \leq 1 \quad \forall c \in \mathcal{C}\]
</blockquote>

<blockquote class="block-tip">
  <p><em>Each column must contain one queen at most:</em></p>

\[\displaystyle \sum_{c \in \mathcal{C}} x_{rc} \leq 1 \quad \forall r \in \mathcal{R}\]
</blockquote>

<blockquote class="block-tip">
  <p><em>Each diagonal can contain at most one queen:</em></p>

\[\displaystyle \sum_{(r,c):r-c=k} x_{rc} \leq 1 \quad \forall k = -(-|\mathcal{C}|-1),\ldots,(|\mathcal{R}|-1)\]

\[\displaystyle \sum_{(r,c):r+c=k} x_{rc} \leq 1 \quad \forall k = 2,\ldots,|\mathcal{R}|+|\mathcal{C}|\]
</blockquote>

<blockquote class="block-tip">
  <p><em>Variables domain</em></p>

\[x_{rc} \in \{0,1\} \quad \forall r \in \mathcal{R}, c \in \mathcal{C}\]
</blockquote>

<hr />

<p><strong>Notes for the reader:</strong></p>
<ul>
  <li>This model allows solving the n-queens problem using <strong>binary linear programming solvers</strong> like Gurobi.</li>
  <li>Although this approach is more mathematical than manually placing the queens, it demonstrates how <strong>optimization modeling</strong> can systematically solve combinatorial logic problems.</li>
</ul>]]></content><author><name></name></author><category term="modelling" /><category term="game" /><category term="chess" /><category term="n-queens" /><category term="non-attacking" /><category term="chessboard" /><summary type="html"><![CDATA[Modelling maximum non-attacking queens on a chessboard]]></summary></entry><entry><title type="html">Sudoku Meets Linear Optimization</title><link href="https://fjmartincampo.github.io/blog/2025/sudoku/" rel="alternate" type="text/html" title="Sudoku Meets Linear Optimization" /><published>2025-12-07T16:00:00+01:00</published><updated>2025-12-07T16:00:00+01:00</updated><id>https://fjmartincampo.github.io/blog/2025/sudoku</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2025/sudoku/"><![CDATA[<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/sudoku-480.webp 480w,/assets/img/sudoku-800.webp 800w,/assets/img/sudoku-1400.webp 1400w," type="image/webp" sizes="95vw" />
      
    
    <img src="/assets/img/sudoku.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

    </div>
</div>

<p>Sudoku is a logic-based number puzzle played on a $9 \times 9$ grid, divided into nine smaller $3 \times 3$ blocks. The goal is to fill the grid with digits from $1$ to $9$ in such a way that each number appears <strong>exactly once</strong> in every row, column, and block.</p>

<p>The modern version of Sudoku was popularized in the late 1980s by the Japanese puzzle company <strong>Nikoli</strong>, although its roots go back earlier to a puzzle called “Number Place” published in the United States in 1979. Interestingly, the name “Sudoku” is an abbreviation of the Japanese phrase <em>“Sūji wa dokushin ni kagiru”</em>, which means <em>“the digits must be single”</em> or <em>“the digits must occur only once”</em>. Sudoku puzzles have since become a global phenomenon, appearing in newspapers, books, and apps, and they are enjoyed by millions for their combination of <strong>logic, pattern recognition, and problem-solving</strong>.</p>

<p>A valid Sudoku puzzle starts with some cells already filled, and the player must deduce the remaining numbers using <strong>logical reasoning</strong>, rather than guessing. For instance, consider the following Sudoku:</p>

<div class="row justify-content-center">
  <div class="col-auto">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/sudoku.svg" sizes="95vw" />
      
    
    <img src="/assets/img/sudoku.svg" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

  </div>
</div>

<p>This Sudoku can be solved as follows:</p>

<div class="row justify-content-center">
  <div class="col-auto">
    



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
        <source class="responsive-img-srcset" srcset="/assets/img/sudoku2.svg" sizes="95vw" />
      
    
    <img src="/assets/img/sudoku2.svg" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />
  </picture>

  
</figure>

  </div>
</div>

<p>To model Sudoku as a <strong>binary linear optimization problem</strong>, we need to first define all the components of the model.</p>

<blockquote class="block-tip">
  <p><em>Sets of indices</em></p>
  <ul>
    <li>\(\mathcal{R}\): Rows of the board.</li>
    <li>\(\mathcal{C}\): Columns of the board.</li>
    <li>\(\mathcal{N}\): Numbers used in the puzzle.</li>
  </ul>
</blockquote>

<blockquote class="block-tip">
  <p><em>Parameters</em></p>
  <ul>
    <li>\(A_{rc}\): Matrix representing the initial Sudoku board (with missing values set to 0).</li>
  </ul>
</blockquote>

<blockquote class="block-tip">
  <p><em>Decision variables</em></p>
  <ul>
    <li>\(x_{rcn} = 1\) if number $n$ is placed in row $r$ and column $c$, and $0$ otherwise.</li>
  </ul>
</blockquote>

<p>In Sudoku, each puzzle typically has a <strong>unique solution</strong> (or if multiple solutions exist, all of them satisfy the same Sudoku rules). Therefore, the <strong>objective function</strong> is not critical here. For the purpose of modeling, it is sufficient to minimize a constant ($L$):</p>

<blockquote class="block-tip">
  <p><em>Objective function</em></p>

\[\min z = L\]
</blockquote>

<p>Next, we define the <strong>constraints</strong> that enforce the rules of Sudoku.</p>

<blockquote class="block-tip">
  <p><em>Each cell must contain exactly one number:</em></p>

\[\displaystyle \sum_{n \in \mathcal{N}} x_{rcn} = 1 \quad \forall r \in \mathcal{R}, c \in \mathcal{C}\]
</blockquote>

<blockquote class="block-tip">
  <p><em>Each number must appear exactly once in each row:</em></p>

\[\displaystyle \sum_{r \in \mathcal{R}} x_{rcn} = 1 \quad \forall c \in \mathcal{C}, n \in \mathcal{N}\]
</blockquote>

<blockquote class="block-tip">
  <p><em>Each number must appear exactly once in each column:</em></p>

\[\displaystyle \sum_{c \in \mathcal{C}} x_{rcn} = 1 \quad \forall r \in \mathcal{R}, n \in \mathcal{N}\]
</blockquote>

<blockquote class="block-tip">
  <p><em>Each number must appear exactly once in each $3 \times 3$ block:</em></p>

\[\displaystyle \sum_{r=3p-2}^{3p} \sum_{c=3q-2}^{3q} x_{rcn} = 1 \quad \forall n \in \mathcal{N}, \; p,q \in \{1,2,3\}\]
</blockquote>

<p>Finally, we define the <strong>domain of the decision variables</strong>:</p>

<blockquote class="block-tip">
  <p><em>Variables’ domain</em></p>

\[x_{rcn} \in \{0,1\} \quad \forall r \in \mathcal{R}, c \in \mathcal{C}, n \in \mathcal{N}\]
</blockquote>

<hr />

<p><strong>Notes for readers:</strong></p>
<ul>
  <li>This formulation allows you to solve Sudoku puzzles using standard <strong>binary linear programming optimizers</strong> such as Gurobi or CPLEX.</li>
  <li>While this approach is more mathematical than typical human-solving methods, it demonstrates the power of <strong>optimization modelling</strong> in combinatorial problems.</li>
</ul>]]></content><author><name></name></author><category term="modelling" /><category term="game" /><category term="sudoku" /><summary type="html"><![CDATA[Modelling a sudoku]]></summary></entry></feed>