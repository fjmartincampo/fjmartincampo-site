<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://fjmartincampo.github.io/spanish/feed.xml" rel="self" type="application/atom+xml"/><link href="https://fjmartincampo.github.io/spanish/" rel="alternate" type="text/html"/><updated>2026-02-12T23:08:13+00:00</updated><id>https://fjmartincampo.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">La anatomía de un problema de optimización lineal</title><link href="https://fjmartincampo.github.io/spanish/blog/2026/theoreticalLO/" rel="alternate" type="text/html" title="La anatomía de un problema de optimización lineal"/><published>2026-02-01T00:05:00+00:00</published><updated>2026-02-01T00:05:00+00:00</updated><id>https://fjmartincampo.github.io/blog/2026/theoreticalLO</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/theoreticalLO/"><![CDATA[<div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/theoryLO-480.webp 480w,/assets/img/theoryLO-800.webp 800w,/assets/img/theoryLO-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/theoryLO.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>La optimización lineal es mucho más que una herramienta para resolver problemas prácticos de producción, logística o asignación de recursos: también constituye un objeto profundamente elegante desde el punto de vista teórico.</p> <p>Detrás de cada solución óptima se esconden estructuras geométricas y algebraicas que nos permiten comprender:</p> <ul> <li><strong>cuándo</strong> existen soluciones óptimas,</li> <li><strong>cómo</strong> se alcanzan,</li> <li>y de qué manera puede describirse el conjunto completo de soluciones factibles.</li> </ul> <p>Este post explora los conceptos fundamentales que sustentan la teoría de la optimización lineal:</p> <ul> <li>los <strong>puntos extremos</strong>,</li> <li>las <strong>direcciones extremas</strong>,</li> <li>cómo caracterizarlos,</li> <li>y el <strong>teorema de representación</strong> para el conjunto de soluciones factibles.</li> </ul> <p>El objetivo es proporcionar un marco conceptual claro que ayude a entender el <em>por qué</em> detrás de algoritmos como el Símplex, más allá del simple cálculo mecánico de una solución óptima. En optimización lineal, lo verdaderamente interesante no es solo encontrar el óptimo, sino comprender la geometría que hay detrás.</p> <h2 id="notación-y-definiciones">Notación y definiciones</h2> <p>El problema de optimización lineal en su forma estándar se escribe como:</p> \[\begin{aligned} \min \;\; &amp; z = \mathbf{c}^\intercal \mathbf{x} \\ \text{s.a:}\;\; &amp; \mathbf{A}\mathbf{x} = \mathbf{b} \\ &amp; \mathbf{x} \geqslant \mathbf{0}. \end{aligned}\] <p>El <strong>conjunto de soluciones factibles</strong> se define como:</p> \[\mathcal{S}=\{\mathbf{x} \in \mathbb{R}^n : \mathbf{A}\mathbf{x} = \mathbf{b},\; \mathbf{x}\geqslant \mathbf{0}\}.\] <p>La matriz de coeficientes técnicos \(\mathbf{A}\in\mathbb{R}^{m\times n}\) puede interpretarse como un conjunto de $n$ vectores en \(\mathbb{R}^m\):</p> \[\mathbf{A} = (\mathbf{a}_1,\ldots,\mathbf{a}_n),\] <p>donde cada columna es:</p> \[\mathbf{a}_j = \begin{pmatrix} a_{1j} \\ a_{2j} \\ \vdots \\ a_{mj} \end{pmatrix}, \qquad j=1,\ldots,n.\] <h3 id="bases-y-soluciones-básicas">Bases y soluciones básicas</h3> <p>Un supuesto habitual en la teoría es que la matriz \(\mathbf{A}\) tiene rango máximo:</p> \[\mathrm{rg}(\mathbf{A}) = m.\] <p>En ese caso, existe al menos una submatriz cuadrada</p> \[\mathbf{B}\in\mathbb{R}^{m\times m}, |\mathbf{B}| \neq 0.\] <p>llamada <strong>base</strong>.</p> <blockquote class="block-tip"> <p>Los $m$ vectores columna que forman la base \(\mathbf{B}\) son linealmente independientes.</p> </blockquote> <p>Elegir una base permite descomponer la matriz como:</p> \[\mathbf{A} = (\mathbf{B},\mathbf{N}),\] <p>lo que induce una partición natural del vector solución:</p> \[\mathbf{x} = \begin{pmatrix} \mathbf{x}_{\mathbf{B}} \\ \mathbf{x}_{\mathbf{N}} \end{pmatrix},\] <p>donde:</p> <ul> <li>\(\mathbf{x}_{\mathbf{B}}\in\mathbb{R}^m\) son las <strong>variables básicas</strong>,</li> <li>\(\mathbf{x}_{\mathbf{N}}\in\mathbb{R}^{n-m}\) son las <strong>variables no básicas</strong>.</li> </ul> <h3 id="solución-básica">Solución básica</h3> <blockquote class="block-tip"> <p>Se dice que \(\mathbf{x}\in\mathbb{R}^n\) es una <strong>solución básica</strong> si existe una base \(\mathbf{B}\subset\mathbf{A}\) tal que las variables no básicas son cero:</p> \[\mathbf{x} = \begin{pmatrix} \mathbf{B}^{-1}\mathbf{b} \\ \mathbf{0} \end{pmatrix}.\] </blockquote> <h3 id="solución-básica-factible">Solución básica factible</h3> <blockquote class="block-tip"> <p>Una solución básica se dice <strong>factible</strong> si además satisface la condición de no negatividad:</p> \[\mathbf{B}^{-1}\mathbf{b}\geqslant 0.\] </blockquote> <p>Las soluciones básicas factibles son especialmente importantes porque están directamente relacionadas con los <strong>puntos extremos</strong> de la región factible, como veremos en las siguientes secciones.</p> <h2 id="convexidad">Convexidad</h2> <p>Uno de los aspectos más profundos detrás del análisis teórico de la optimización lineal es la <strong>convexidad</strong>.</p> <blockquote class="block-tip"> <p>Un conjunto no vacío \(\mathcal{C} \subset \mathbb{R}^n\) se dice que es <strong>convexo</strong> si:</p> \[\lambda \mathbf{x} + (1-\lambda)\mathbf{y} \in \mathcal{C} \qquad \forall \mathbf{x},\mathbf{y}\in\mathcal{C},\; \forall \lambda\in[0,1].\] </blockquote> <p>Geométricamente, esto significa que dados dos puntos cualesquiera del conjunto, el segmento que los une permanece completamente dentro del conjunto.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/conv-480.webp 480w,/assets/img/conv-800.webp 800w,/assets/img/conv-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/conv.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Conjunto convexo" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/noconv-480.webp 480w,/assets/img/noconv-800.webp 800w,/assets/img/noconv-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/noconv.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Conjunto no convexo" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <blockquote class="block-tip"> <p>El conjunto de soluciones factibles de un problema de optimización lineal,</p> \[\mathcal{S}=\{\mathbf{x}\in\mathbb{R}^n:\mathbf{A}\mathbf{x}=\mathbf{b},\;\mathbf{x}\geqslant 0\},\] <p>es un conjunto convexo.</p> </blockquote> <h2 id="puntos-extremos">Puntos extremos</h2> <p>Aunque \(\mathcal{S}\) contiene infinitos puntos, su estructura está determinada por un conjunto más pequeño de elementos especiales: los <strong>puntos extremos</strong>, que representan los “vértices” del <em>politopo</em> factible.</p> <blockquote class="block-tip"> <p>Si existe una solución óptima, entonces puede encontrarse en un punto extremo.</p> </blockquote> <p>Por tanto, es importante entender qué son los puntos extremos y cómo caracterizarlos.</p> <blockquote class="block-tip"> <p>Dado un conjunto convexo \(\mathcal{C}\subset\mathbb{R}^n\), un punto \(\mathbf{x}\in\mathcal{C}\) se dice <strong>punto extremo</strong> si:</p> \[\mathbf{x}=\lambda\mathbf{y}+(1-\lambda)\mathbf{z}, \;0&lt;\lambda&lt;1, \;\mathbf{y},\mathbf{z}\in\mathcal{C} \Rightarrow\] \[\mathbf{x}=\mathbf{y}=\mathbf{z}.\] </blockquote> <p>Es decir, un punto extremo no puede escribirse como combinación convexa de otros dos puntos distintos del conjunto.</p> <blockquote class="block-tip"> <p><em>Caracterización de puntos extremos</em></p> <p>Sea \(\mathcal{S}=\{\mathbf{x}\in\mathbb{R}^n:\mathbf{A}\mathbf{x}=\mathbf{b},\;\mathbf{x}\geqslant 0\},\) donde \(\mathbf{A}\in\mathbb{R}^{m\times n}\) y \(\mathrm{rg}(\mathbf{A})=m\). Entonces:</p> <p>\(\bar{\mathbf{x}}\) es punto extremo de \(\mathcal{S}\) si y sólo si</p> <p>\(\exists\,\mathbf{B}\subset\mathbf{A}\) tal que \(|\mathbf{B}|\neq 0, \;\mathbf{B}^{-1}\mathbf{b}\geqslant 0.\)</p> <p>En cuyo caso:</p> \[\bar{\mathbf{x}}= \begin{pmatrix} \mathbf{B}^{-1}\mathbf{b}\\ \mathbf{0} \end{pmatrix}.\] </blockquote> <p>El número de puntos extremos está acotado por:</p> \[\binom{n}{m}.\] <p>Si $\mathcal{S} \neq \emptyset$, existe al menos un punto extremo.</p> <h2 id="direcciones-extremas">Direcciones extremas</h2> <p>En problemas con regiones factibles <strong>no acotadas</strong> aparecen las <strong>direcciones extremas</strong>, que describen cómo el conjunto puede extenderse hacia el infinito.</p> <blockquote class="block-tip"> <p>Un vector \(\mathbf{d}\neq 0\) es una <strong>dirección</strong> de un conjunto convexo \(\mathcal{C}\) si:</p> \[\forall\mathbf{x}\in\mathcal{C},\; \forall\mu\geqslant 0 \Rightarrow \mathbf{x}+\mu\mathbf{d}\in\mathcal{C}.\] <p>Dos direcciones \(\mathbf{d}^1\) y \(\mathbf{d}^2\) son equivalentes si \(\mathbf{d}^1=\alpha\mathbf{d}^2,\; \alpha&gt;0.\)</p> </blockquote> <p>En el problema de optimización lineal,</p> <blockquote class="block-tip"> <p>Dado el conjunto de soluciones factibles de un problema de optimización lineal, $\mathcal{S}={\mathbf{x} \in \mathbb{R}^n : \mathbf{A}\mathbf{x} = \mathbf{b}, \mathbf{x} \geqslant \mathbf{0}}$ entonces,</p> <p>\(\mathbf{d}\) es dirección de \(\mathcal{S}\) si y sólo si \(\mathbf{d} \geqslant \mathbf{0}, \; \mathbf{d} \neq \mathbf{0}\) y \(\mathbf{A}\mathbf{d} = \mathbf{0}\)</p> </blockquote> <blockquote class="block-tip"> <p>Dado un conjunto convexo $\mathcal{C} \subset \mathbb{R}^n$, una dirección $\mathbf{d} \in \mathbb{R}^n$ es una <strong>dirección extrema</strong> en $\mathcal{C}$ si, cuando se expresa como:</p> \[\mathbf{d} = \mu_1 \mathbf{d}^1 + \mu_2 \mathbf{d}^2\] <p>donde $\mu_1,\mu_2 &gt; 0$ y $\mathbf{d}^1,\mathbf{d}^2$ son direcciones de $\mathcal{C}$, se concluye que las tres direcciones son necesariamente equivalentes:</p> \[\mathbf{d} \simeq \mathbf{d}^1 \simeq \mathbf{d}^2\] </blockquote> <p>Las direcciones extremas también se pueden caracterizar.</p> <blockquote class="block-tip"> <p><em>Caracterización de direcciones extremas</em></p> <p>Dado $\mathcal{S}={\mathbf{x} \in \mathbb{R}^n : \mathbf{A}\mathbf{x} = \mathbf{b}, \mathbf{x} \geqslant \mathbf{0}}$, donde $\mathbf{A}$ es una matriz $m \times n$ y $\mathrm{rg}(\mathbf{A}) = m,$ entonces:</p> <p>$\mathbf{d}$ es una dirección extrema de $\mathcal{S}$ si y sólo si \(\exists \mathbf{B} \subset \mathbf{A},\) donde $|\mathbf{B}| \neq 0$ tal que $\mathbf{A}=(\mathbf{B},\mathbf{N})$ y, existe un vector columna $\mathbf{a}_j \in \mathbf{N}$ que cumple $\mathbf{B}^{-1}\mathbf{a}_j \leqslant \mathbf{0}$ de modo que $\mathbf{d}=\alpha\mathbf{d}^0,$ donde $\alpha &gt; 0$ y $\mathbf{d}^0 = \begin{pmatrix}-\mathbf{B}^{-1} \mathbf{a}_j \ \mathbf{e}_j\end{pmatrix}$.</p> <p>$\mathbf{e}_j$ es un vector cuyas componentes son todas nulas excepto la $j$-ésima que toma valor 1.</p> </blockquote> <p>El número de direcciones extremas está acotado por:</p> \[\binom{n}{m+1}.\] <h2 id="teorema-de-representación">Teorema de Representación</h2> <p>El teorema de representación es la consecuencia de un conjunto de teoremas de representación gracias a los trabajos de <a href="https://es.wikipedia.org/wiki/Hermann_Minkowski">Minkowski</a>, <a href="https://en.wikipedia.org/wiki/Constantin_Carathéodory">Carathéodory</a>, <a href="https://en.wikipedia.org/wiki/Ernst_Steinitz">Steinitz</a>, <a href="https://en.wikipedia.org/wiki/Hermann_Weyl">Weyl</a> and <a href="https://en.wikipedia.org/wiki/Theodore_Motzkin">Motzkin</a> (<a class="citation" href="#Minkowski1897">(Minkowski, 1897)</a>, <a class="citation" href="#Caratheodory1907">(Carathéodory, 1907)</a>, <a class="citation" href="#Steinitz1916">(Steinitz, 1916)</a>, <a class="citation" href="#Weyl1935">(Weyl, 1935)</a> y <a class="citation" href="#Motzkin1936">(Motzkin, 1936)</a>) para conjuntos convexos que se demostraron con anterioridad al nacimiento de la optimización lineal.</p> <blockquote class="block-tip"> <p><em>Teorema de Representación</em></p> <p>Dado el conjunto de soluciones factibles del problema de optimización lineal $\mathcal{S}={\mathbf{x} \in \mathbb{R}^n : \mathbf{A}\mathbf{x} = \mathbf{b}, \mathbf{x} \geqslant \mathbf{0}}$, donde $\mathbf{A}$ es una matriz $m \times n$ y $\mathrm{rg}(\mathbf{A}) = m$, sea ${\mathbf{x}^1,\ldots,\mathbf{x}^k}$ el conjunto de puntos extremos de $\mathcal{S}$ y sea ${\mathbf{d}^1,\ldots,\mathbf{d}^l}$ el conjunto de sus direcciones extremas, entonces se verifica que:</p> \[\mathbf{x} \in \mathcal{S} \Leftrightarrow \wedge \begin{cases} \exists (\lambda_1,\ldots,\lambda_k) &amp; \lambda_i \geqslant 0, \; \forall i=1,\ldots,k : \displaystyle \sum_{i=1}^k \lambda_i = 1 \\ \exists (\mu_1,\ldots,\mu_l) &amp; \mu_j \geqslant 0, \; \forall j=1,\ldots,l\end{cases}\] <p>de modo que:</p> \[\mathbf{x} = \sum_{i=1}^k \lambda_i \mathbf{x}^i + \sum_{j=1}^l \mu_j \mathbf{d}^j\] </blockquote> <p>Este teorema permite definir cualquier solución del problema de optimización lineal en función de sus puntos extremos y direcciones extremas. Para ello, es necesario proporcionar estos dos conjuntos, usando los teoremas de caracterización presentados anteriormente.</p> <h3 id="ejemplos">Ejemplos</h3> <p>Sea el conjunto de soluciones factibles (independiente de la función objetivo) de un problema de optimización lineal y su formulación estándar (añadiendo variables de holgura):</p> \[\begin{aligned} -x_1 + x_2 &amp; \leqslant 2 \\ x_1 - 2x_2 &amp; \leqslant 2 \\ x_1, x_2 &amp; \geqslant 0 \end{aligned} \qquad \begin{aligned} -x_1 + x_2 + x_3^h &amp; = 2 \\ x_1 - 2x_2 + x_4^h &amp; = 2 \\ x_1, x_2, x_3^h, x_4^h &amp; \geqslant 0 \end{aligned}\] <p>Este problema tiene un total de 3 puntos extremos:</p> \[\mathbf{x}_1 = \begin{pmatrix}0 \\ 0 \\ 2 \\ 2\end{pmatrix} \qquad \mathbf{x}_2 = \begin{pmatrix}2 \\ 0 \\ 4 \\ 0\end{pmatrix} \qquad \mathbf{x}_3 = \begin{pmatrix}0 \\ 2 \\ 0 \\ 6\end{pmatrix}\] <p>y dos direcciones extremas:</p> \[\mathbf{d}_1 = \begin{pmatrix}1 \\ 1 \\ 0 \\ 1\end{pmatrix} \qquad \mathbf{d}_2 = \begin{pmatrix}2 \\ 1 \\ 1 \\ 0\end{pmatrix}\] <p>que se representan en la siguiente figura, en $\mathbb{R}^2$:</p> <div class="row justify-content-center"> <div class="col-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teorrep-480.webp 480w,/assets/img/teorrep-800.webp 800w,/assets/img/teorrep-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/teorrep.jpg" class="img-responsive img-fluid rounded z-depth-1" width="100%" height="auto" title="Ejemplo teorema de representación" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Usando el teorema de representación, el conjunto $\mathcal{S}$ se puede expresar:</p> \[\begin{aligned} \mathcal{S} =\Biggl\{ &amp;\lambda_1 \begin{pmatrix} 0\\0\\2\\2 \end{pmatrix} +\lambda_2 \begin{pmatrix} 2\\0\\4\\0 \end{pmatrix} +\lambda_3 \begin{pmatrix} 0\\2\\0\\6 \end{pmatrix} +\mu_1 \begin{pmatrix} 1\\1\\0\\1 \end{pmatrix} +\mu_2 \begin{pmatrix} 2\\1\\1\\0 \end{pmatrix} : \\[0.4em] &amp; \lambda_1+\lambda_2+\lambda_3=1, \lambda_1,\lambda_2,\lambda_3\geqslant 0, \qquad \mu_1,\mu_2\geqslant 0 \Biggr\}. \end{aligned}\] <h3 id="consecuencias-del-teorema-de-representación">Consecuencias del teorema de representación</h3> <p>El teorema de representación permite categorizar los distintos tipos de soluciones del problema de optimización lineal de minimización.</p> <ul> <li>Solución óptima no acotada si existe dirección extrema $\mathbf{d}^j$ con $\mathbf{c}^\intercal \mathbf{d}^j &lt; 0$.</li> <li>Solución óptima si todas las direcciones extremas cumplen $\mathbf{c}^\intercal \mathbf{d}^j \geqslant 0$ o no existen direcciones extremas, alcanzándose en un punto extremo.</li> </ul> <h2 id="procedimiento-de-resolución-y-combinatoria">Procedimiento de resolución y combinatoria</h2> <p>En el conjunto de restricciones mostrado anteriormente, se analizarán diferentes vectores de coste que proporcionan diferentes funciones objetivo y, por tanto, diferentes tipos de solución final.</p> <ul> <li>$\mathbf{c}^\intercal = (2,-3,0,0)$</li> </ul> <p>\(\mathbf{c}^\intercal \mathbf{d}^1 = (2,-3,0,0)\begin{pmatrix}1 \\ 1 \\ 0 \\ 1\end{pmatrix} = -1 &lt; 0\), el problema tiene solución óptima no acotada.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teorrep1-480.webp 480w,/assets/img/teorrep1-800.webp 800w,/assets/img/teorrep1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/teorrep1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Solución óptima no acotada" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ul> <li>$\mathbf{c}^\intercal = (4,-3,0,0)$</li> </ul> <p>\(\mathbf{c}^\intercal \mathbf{d}^1 \geqslant 0\) y \(\mathbf{c}^\intercal \mathbf{d}^2 \geqslant 0\) el problema tiene solución óptima y se alcanza en el vértice cuyo valor en la función objetivo es mínimo, es decir, en $\mathbf{x}^3$ (\(\mathbf{c}^\intercal \mathbf{x}^3 = -6\)).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teorrep2-480.webp 480w,/assets/img/teorrep2-800.webp 800w,/assets/img/teorrep2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/teorrep2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Solución óptima única" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ul> <li>$\mathbf{c}^\intercal = (0,1,0,0)$</li> </ul> <p>\(\mathbf{c}^\intercal \mathbf{d}^1 \geqslant 0\) y \(\mathbf{c}^\intercal \mathbf{d}^2 \geqslant 0\) el problema tiene solución óptima y se alcanza en el vértice cuyo valor en la función objetivo es mínimo. En este caso, hay dos vértices que alcanzan el valor mínimo, $\mathbf{x}^1$ y $\mathbf{x}^2$, donde \(\mathbf{c}^\intercal \mathbf{x}^1 = \mathbf{c}^\intercal \mathbf{x}^2 = 0\).</p> <p>El conjunto de soluciones óptimas del problema viene dado por:</p> \[\left\{\lambda\begin{pmatrix}0 \\ 0 \\ 2 \\ 2\end{pmatrix} + (1-\lambda)\begin{pmatrix}2 \\ 0 \\ 4 \\ 0\end{pmatrix}, \;\; \lambda \in [0,1]\right\}\] <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teorrep3-480.webp 480w,/assets/img/teorrep3-800.webp 800w,/assets/img/teorrep3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/teorrep3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Múltiples soluciones en región acotada" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ul> <li>$\mathbf{c}^\intercal = (1,-1,0,0)$</li> </ul> <p>\(\mathbf{c}^\intercal \mathbf{d}^1 \geqslant 0\) y \(\mathbf{c}^\intercal \mathbf{d}^2 \geqslant 0\), observándose que \(\mathbf{c}^\intercal \mathbf{d}^1 \geqslant 0\), el problema tiene solución óptima. En este caso, evaluando los vértices, el valor mínimo se alcanza en $\mathbf{x}^3$, donde \(\mathbf{c}^\intercal \mathbf{x}^3 = -2\).</p> <p>El conjunto de soluciones óptimas del problema viene dado por:</p> \[\left\{\begin{pmatrix}0 \\ 2 \\ 0 \\ 6\end{pmatrix} + \mu\begin{pmatrix}1 \\ 1 \\ 0 \\ 1\end{pmatrix}, \;\; \mu \geqslant 0 \right\}\] <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teorrep4-480.webp 480w,/assets/img/teorrep4-800.webp 800w,/assets/img/teorrep4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/teorrep4.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Múltiples soluciones en región no acotada" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="combinatoria">Combinatoria</h2> <p>El análisis combinatorio de todas las bases crece muy rápido. Para un problema de pequeñas dimensiones, por ejemplo $n=40$ y $m=20$:</p> \[\binom{40}{20}=137.846.528.820\] <p>Aunque el procedimiento de enumerar todos los puntos extremos y direcciones extremas no es práctico para problemas de gran tamaño debido al crecimiento combinatorio, este análisis proporciona los elementos teóricos fundamentales: nos permite comprender la estructura geométrica de la región factible, caracterizar los tipos de soluciones posibles y sentar las bases para el desarrollo de algoritmos eficientes, como el Símplex, que explotan precisamente estas propiedades.</p>]]></content><author><name></name></author><category term="algorithms"/><category term="OR"/><category term="LinearOptimization"/><category term="concepts"/><category term="resolution"/><summary type="html"><![CDATA[Caracterización geométrica de los problemas de optimización lineal, puntos extremos, direcciones extremas y teorema de representación]]></summary></entry><entry><title type="html">El Algoritmo Símplex, el Motor de la Optimización Matemática</title><link href="https://fjmartincampo.github.io/spanish/blog/2026/simplex/" rel="alternate" type="text/html" title="El Algoritmo Símplex, el Motor de la Optimización Matemática"/><published>2026-02-01T00:05:00+00:00</published><updated>2026-02-01T00:05:00+00:00</updated><id>https://fjmartincampo.github.io/blog/2026/simplex</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/simplex/"><![CDATA[<div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/simplex-480.webp 480w,/assets/img/simplex-800.webp 800w,/assets/img/simplex-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/simplex.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Desde su introducción por <strong><a href="https://en.wikipedia.org/wiki/George_Dantzig">George B. Dantzig</a> en 1947</strong>, el Algoritmo Símplex ha sido calificado como uno de los avances más influyentes en el cálculo científico y la toma de decisiones estratégicas. Su importancia radica en su capacidad para resolver problemas de <strong>optimización lineal</strong>, permitiendo encontrar de forma eficiente el valor óptimo (máximo o mínimo) de una función sujeta a múltiples restricciones de recursos.</p> <p>A diferencia de otros métodos, el Símplex navega de forma inteligente por los vértices de la región factible, garantizando que, si existe una solución óptima, esta será alcanzada en un número finito de pasos.</p> <h2 id="1-el-sistema-explícito-la-base-del-algoritmo">1. El Sistema Explícito: La Base del Algoritmo</h2> <p>Para que el algoritmo pueda evaluar si una solución es óptima o cómo mejorarla, es necesario transformar el problema original en un <strong>sistema explícito</strong> asociado a una base $\mathbf{B}$. Partimos de la forma estándar: \(\min z = \mathbf{c}^\intercal x\) sujeto a \(\mathbf{Ax} = \mathbf{b}\), \(\mathbf{x} \geqslant \mathbf{0}\)</p> <p>Dividiendo las variables en básicas ($x_B$) y no básicas ($x_N$), y multiplicando por la inversa de la base ($B^{-1}$), obtenemos las ecuaciones clave [5, 6]:</p> <ul> <li> <p><strong>Ecuaciones de las variables básicas:</strong> \(x_B = \bar{x}_B - \sum_{j \in J} y_j x_j\) Donde $\bar{x}_B = B^{-1}b$ es la solución básica actual y $y_j = B^{-1}a_j$ [4].</p> </li> <li> <p><strong>Ecuación de costes (Función Objetivo):</strong> \(z = \bar{z} - \sum_{j \in J} (z_j - c_j)x_j\) Aquí, $\bar{z}$ representa el valor actual de la función objetivo y la magnitud $(c_j - z_j)$ nos indica cuánto aumenta (o disminuye) la función por cada unidad que incrementamos la variable no básica $x_j$ [7, 8].</p> </li> </ul> <h2 id="2-los-tres-teoremas-del-símplex">2. Los Tres Teoremas del Símplex</h2> <p>El comportamiento y la lógica de parada del algoritmo se fundamentan en estos tres teoremas esenciales (planteados para un problema de <strong>minimización</strong>):</p> <ol> <li><strong>Primer Teorema (Optimalidad):</strong> Una solución básica factible es óptima si para toda variable no básica se cumple que $z_j - c_j \leq 0$ [9, 10].</li> <li><strong>Segundo Teorema (Solución No Acotada):</strong> Si existe una variable no básica $k$ tal que $z_k - c_k &gt; 0$ y todos los elementos de su vector asociado son no positivos ($y_k \leq 0$), entonces el problema tiene una solución óptima no acotada [11, 12].</li> <li><strong>Tercer Teorema (Mejora de la Solución):</strong> Si para una solución básica factible existe un índice $k$ tal que $z_k - c_k &gt; 0$ y al menos un componente de $y_k$ es positivo ($y_k \not\leq 0$), existe una nueva base $B’$ que proporciona una solución factible con un valor de la función objetivo menor o igual al actual [13, 14].</li> </ol> <h2 id="3-ejemplos-numéricos">3. Ejemplos Numéricos</h2> <p>Para ilustrar estos teoremas, veamos casos extraídos de situaciones reales de cálculo:</p> <h3 id="caso-a-solución-óptima-alcanzada">Caso A: Solución Óptima Alcanzada</h3> <p>En un problema de minimización con base $B_1$, obtenemos los siguientes valores [11, 15]:</p> <ul> <li>$\bar{z} = 6$</li> <li>$z_4 - c_4 = 0$</li> <li>$z_5 - c_5 = -6$ Al ser todos los $z_j - c_j \leq 0$, el <strong>Primer Teorema</strong> garantiza que la solución $(\bar{x}_1=1, \bar{x}_2=1, \bar{x}_3=1, \bar{x}_4=0, \bar{x}_5=0)$ es <strong>óptima</strong> [9, 11].</li> </ul> <h3 id="caso-b-problema-no-acotado">Caso B: Problema No Acotado</h3> <p>Consideremos un sistema donde identificamos una variable $x_2$ tal que [16]:</p> <ul> <li>$z_2 - c_2 = 2$ (Indica que el valor puede seguir bajando).</li> <li>$y_2 = \begin{pmatrix} 0 \ -1 \end{pmatrix}$ (No hay restricciones que detengan el crecimiento de $x_2$). Bajo el <strong>Segundo Teorema</strong>, concluimos que el valor de la función objetivo puede decrecer indefinidamente [16, 17].</li> </ul> <h3 id="caso-c-mejora-mediante-cambio-de-base">Caso C: Mejora mediante Cambio de Base</h3> <p>Si partimos de una base $B_2$ donde $z_2 - c_2 = 6 &gt; 0$ y el vector $y_2$ tiene componentes positivos como $\begin{pmatrix} 1 \ 0 \ 1 \end{pmatrix}$ [18, 19]: El <strong>Tercer Teorema</strong> nos indica que debemos realizar un “pivoteo”. Al introducir $x_2$ en la base y sacar la variable correspondiente (regla del cociente mínimo), logramos una nueva solución factible que mejora (o mantiene) el valor de la función objetivo [13, 20, 21].</p>]]></content><author><name></name></author><category term="algorithms"/><category term="OR"/><category term="LinearOptimization"/><category term="simplex"/><category term="resolution"/><summary type="html"><![CDATA[El método clásico que convirtió la optimización en una herramienta computacional efectiva.]]></summary></entry><entry><title type="html">La resolución gráfica como punto de partida en optimización lineal</title><link href="https://fjmartincampo.github.io/spanish/blog/2026/graphical/" rel="alternate" type="text/html" title="La resolución gráfica como punto de partida en optimización lineal"/><published>2026-01-25T00:05:00+00:00</published><updated>2026-01-25T00:05:00+00:00</updated><id>https://fjmartincampo.github.io/blog/2026/graphical</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/graphical/"><![CDATA[<div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/rulegraphic-480.webp 480w,/assets/img/rulegraphic-800.webp 800w,/assets/img/rulegraphic-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/rulegraphic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>La optimización lineal es una herramienta fundamental para modelar y resolver problemas de toma de decisiones, desde la planificación de la producción hasta la asignación eficiente de recursos.</p> <p>Aunque los problemas reales suelen involucrar un gran número de variables, el caso de <strong>dos variables de decisión</strong> desempeña un papel clave desde el punto de vista pedagógico. En este contexto, el método gráfico permite <strong>ver</strong> literalmente el problema: qué soluciones son posibles, dónde están las restricciones y por qué ciertas soluciones son mejores que otras.</p> <p>El método gráfico consiste en representar cada restricción como una región del plano y observar qué puntos cumplen <strong>todas</strong> ellas simultáneamente. De esta forma, el problema abstracto se convierte en una figura geométrica concreta, lo que facilita enormemente la comprensión del concepto de solución óptima.</p> <h2 id="formulación-del-problema">Formulación del problema</h2> <p>Un problema de optimización lineal con dos variables puede escribirse como:</p> <ul> <li> <p>Función objetivo: \(\max\; z = c_1 x_1 + c_2 x_2\) o \(\min\; z = c_1 x_1 + c_2 x_2\).</p> </li> <li> <p>Sujeto a un conjunto de restricciones lineales: \(a_{i1} x_1 + a_{i2} x_2 \leqslant b_i, \; \forall i = 1, \dots, m\).</p> </li> <li> <p>Variables de decisión: \(x_1, x_2\) que con frecuencia son no negativas, es decir \(x_1, x_2 \geqslant 0\).</p> </li> </ul> <p>El objetivo es encontrar los valores de las variables de decisión, $x_1$ y $x_2$, que optimicen la función objetivo cumpliendo todas las restricciones.</p> <h2 id="representación-gráfica-de-las-restricciones-y-región-factible">Representación gráfica de las restricciones y región factible</h2> <p>Intuitivamente, la región factible recoge <strong>todas las decisiones que son posibles</strong> desde el punto de vista del problema planteado.</p> <p>Cada restricción lineal define un semiplano en el plano $\mathbb{R}^2$. Para representar una restricción gráficamente:</p> <ol> <li>Dibuja la recta correspondiente a la igualdad.</li> <li>Determina qué lado de la recta cumple la desigualdad.</li> <li>Sombrea el semiplano factible.</li> </ol> <p>Las restricciones de no negatividad, en caso de existir, limitan la solución al primer cuadrante.</p> <p>La <strong>región factible</strong> es la intersección de todos los semiplanos definidos por las restricciones.</p> <p>Desde el punto de vista geométrico, esta región presenta una serie de propiedades fundamentales.</p> <ul> <li>La región factible es un conjunto convexo.</li> <li>La región factible puede estar acotada o no acotada. En caso de estar acotada, la región factible es un polígono.</li> <li>Toda solución factible se encuentra dentro o sobre el límite de esta región.</li> </ul> <p>Si la región factible es vacía, se dice que el problema es <strong>infactible</strong>, es decir, no hay ninguna solución que verifique todas las restricciones impuestas al problema.</p> <h2 id="función-objetivo-y-optimalidad">Función objetivo y optimalidad</h2> <p>La función objetivo puede interpretarse como una familia de rectas paralelas:</p> \[z := c_1 x_1 + c_2 x_2 = k\] <p>donde cada valor de $k$ corresponde a una recta diferente. Maximizar (o minimizar) la función objetivo $z$ consiste en mover esta recta en la dirección de mejora definida por los coeficientes de la función objetivo mientras siga intersecándose con la región factible.</p> <p>Gráficamente, la solución óptima se encuentra donde la recta de la función objetivo toca por última vez la región factible. Esto suele ocurrir en un <strong>vértice</strong> o <strong>punto extremo</strong>, aunque pueden existir múltiples soluciones óptimas a lo largo de un borde, ya sea un segmento (región acotada) o una semirrecta (región no acotada).</p> <p>Este razonamiento geométrico conduce a un resultado fundamental de la optimización lineal:</p> <blockquote class="block-tip"> <p>Si existe una solución óptima, entonces al menos una solución óptima se encuentra en un vértice de la región factible.</p> </blockquote> <p>Pueden surgir varias situaciones:</p> <blockquote class="block-tip"> <ul> <li><strong>Solución óptima única</strong>: la función objetivo, en su óptimo, toca la región factible en un solo vértice.</li> <li><strong>Múltiples soluciones óptimas</strong>: <ul> <li><strong>Región acotada</strong>: la función objetivo, en su óptimo, es coincidente con un segmento en el borde de la región factible, es decir, un lado del polígono.</li> <li><strong>Región no acotada</strong>: la función objetivo, en su óptimo, es coincidente con una semirrecta en el borde de la región factible (es necesario que la región factible no esté acotada).</li> </ul> </li> <li><strong>Solución óptima no acotada</strong>: la función objetivo puede mejorar indefinidamente.</li> <li><strong>Problema infactible</strong>: no existe solución, es decir, la región factible es vacía.</li> </ul> </blockquote> <p>Es importante señalar que en problemas reales es muy difícil encontrar regiones factibles no acotadas, ya que las variables de decisión suelen estar relacionadas con recursos o decisiones que están acotadas por ser finitos.</p> <h2 id="ejemplos-ilustrativos">Ejemplos ilustrativos</h2> <p>Con el objetivo de mostrar las distintas situaciones, se presentan a continuación los siguientes ejemplos ilustrativos, indicando su formulación matemática y su resolución gráfica de forma dinámica.</p> <h3 id="solución-óptima-única">Solución óptima única</h3> <p>Sea el siguiente problema de optimización lineal:</p> \[\begin{aligned} \max\;\;&amp; z = 6x_1 + 3x_2 \\ \text{s. a:}\;\;&amp; 2x_1 + 4x_2 \leqslant 8 \\ &amp; -x_1 + 4x_2 \leqslant 4 \\ &amp; x_1 - x_2 \leqslant 2 \\ &amp; x_1, x_2 \geqslant 0 \end{aligned}\] <p>En la siguiente animación se observa cómo se construye progresivamente la región factible y cómo la recta de la función objetivo se desplaza hasta alcanzar el óptimo en un vértice.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Unique-480.webp 480w,/assets/img/Unique-800.webp 800w,/assets/img/Unique-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Unique.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Solución óptima única" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Se puede observar que la solución óptima se encuentra en el vértice $D=(8/3,2/3)^\intercal$ obteniendo un valor en la función objetivo, tras sustituir los valores de $x_1$ y $x_2$, de $z^* = 18$.</p> <h3 id="múltiples-soluciones-óptimas-en-una-región-acotada">Múltiples soluciones óptimas en una región acotada</h3> <p>Sea el siguiente problema de optimización lineal:</p> \[\begin{aligned} \max\;\;&amp; z = x_1 + x_2 \\ \text{s. a:}\;\;&amp; x_1 + x_2 \leqslant 8 \\ &amp; -4x_1 + 4x_2 \leqslant 8 \\ &amp; 2x_1 - x_2 \leqslant 6 \\ &amp; x_1, x_2 \geqslant 0 \end{aligned}\] <p>La animación muestra cómo, en este caso, la recta de la función objetivo coincide con un lado completo de la región factible.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/MultipleBounded-480.webp 480w,/assets/img/MultipleBounded-800.webp 800w,/assets/img/MultipleBounded-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/MultipleBounded.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Soluciones óptimas múltiples en región acotada" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Los vértices $C=(3,5)^\intercal$ y $D=(14/3,10/3)^\intercal$ son soluciones óptimas, además de todos los puntos del segmento que los une. Por tanto, las soluciones óptimas del problema son la combinación lineal convexa entre ambos puntos $C$ y $D$ y vienen dadas por:</p> \[\lambda \left(\begin{array}{c} 3 \\ 5\end{array}\right) + (1-\lambda) \left(\begin{array}{c} 14/3 \\ 10/3\end{array}\right) \quad \lambda \in [0,1]\] <p>con un valor de la función objetivo $z^*=8$.</p> <h3 id="múltiples-soluciones-óptimas-en-una-región-no-acotada">Múltiples soluciones óptimas en una región no acotada</h3> <p>Sea el siguiente problema de optimización lineal:</p> \[\begin{aligned} \min\;\;&amp; z = x_1 \\ \text{s. a:}\;\;&amp; x_1 - x_2 \leqslant 2 \\ &amp; 2x_1 + 2x_2 \geqslant 1 \\ &amp; x_1, x_2 \geqslant 0 \end{aligned}\] <p>La animación muestra cómo, en este caso también, la recta de la función objetivo coincide con un lado completo de la región factible.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/MultipleUnbounded-480.webp 480w,/assets/img/MultipleUnbounded-800.webp 800w,/assets/img/MultipleUnbounded-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/MultipleUnbounded.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Soluciones óptimas múltiples en región no acotada" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>El vértice $C=(0,1/2)^\intercal$ es solución óptima junto al conjunto de puntos que se encuentran en la semirrecta que parte de $C$ hacia la parte positiva del eje de ordenadas. Las soluciones óptimas del problema vienen dadas por:</p> \[\left(\begin{array}{c} 0 \\ 1/2\end{array}\right) + \mu \left(\begin{array}{c} 0 \\ 1 \end{array}\right) \quad \mu \geqslant 0\] <p>donde se tiene en cuenta el vértice obtenido y el vector que define la dirección de la semirrecta hacia donde se encuentran las soluciones óptimas del problema, o <strong>dirección extrema</strong>. Todos estos puntos producen el mismo valor de la función objetivo, $z^*=0$.</p> <h3 id="solución-óptima-no-acotada">Solución óptima no acotada</h3> <p>Sea el siguiente problema de optimización lineal:</p> \[\begin{aligned} \max\;\;&amp; z = x_1 + 2x_2 \\ \text{s. a:}\;\;&amp; x_1 + 2x_2 \geqslant 2 \\ &amp; -2x_1 + x_2 \leqslant 4 \\ &amp; x_1, x_2 \geqslant 0 \end{aligned}\] <p>La animación muestra cómo, en este caso, la recta de la función objetivo puede desplazarse mejorando la solución obtenida sin límite.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Unbounded-480.webp 480w,/assets/img/Unbounded-800.webp 800w,/assets/img/Unbounded-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Unbounded.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Solución óptima no acotada" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Siguiendo la dirección de mejora de la función objetivo no se llega a ningún vértice pudiendo mejorar la función objetivo tanto como se desee. En este caso, el valor óptimo de la función objetivo es $z^* = \infty$.</p> <h3 id="problema-infactible">Problema infactible</h3> <p>Sea el siguiente problema de optimización lineal:</p> \[\begin{aligned} \min\;\;&amp; z = x_1 + x_2 \\ \text{s. a:}\;\;&amp; 2x_1 + x_2 \leqslant 5 \\ &amp; x_1 - x_2 \geqslant 4 \\ &amp; x_1, x_2 \geqslant 0 \end{aligned}\] <p>La animación muestra cómo, en este caso, no hay intersección del primer cuadrante con las dos restricciones planteadas.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Infeasible-480.webp 480w,/assets/img/Infeasible-800.webp 800w,/assets/img/Infeasible-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Infeasible.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Problema infactible" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Se observa que la región factible es vacía y, por tanto, el problema es infactible, no existe ninguna solución que satisfaga el conjunto de restricciones del problema.</p> <p>En todos los casos estudiados se observa que el comportamiento de la solución depende exclusivamente de la geometría de la región factible y de la dirección de la función objetivo. Es importante tener en cuenta que la recta de la función objetivo debe moverse en la dirección correcta en función del criterio de optimización (maximización o minimización) y que no se confundan los términos <strong>región no acotada</strong> con <strong>solución óptima no acotada</strong>.</p> <blockquote class="block-tip"> <p>En dos dimensiones, resolver un problema de optimización lineal consiste en:</p> <ol> <li>Construir la región factible.</li> <li>Identificar sus vértices y direcciones extremas.</li> <li>Desplazar la recta objetivo en la dirección correcta.</li> <li>Analizar el punto o conjunto de puntos donde se alcanza el óptimo (si existe).</li> </ol> </blockquote> <h2 id="limitaciones-del-método-gráfico">Limitaciones del método gráfico</h2> <p>El enfoque gráfico está limitado a problemas con dos o tres variables de decisión. Para problemas de mayor dimensión se requieren métodos algorítmicos como el Algoritmo del Símplex o Métodos de Punto Interior.</p> <p>No obstante, la intuición geométrica adquirida en dos dimensiones sigue siendo válida y sirve como base para entender técnicas más avanzadas. Hemos podido observar que:</p> <ul> <li>Convexidad: El conjunto de soluciones del problema es convexo.</li> <li>Vértices o puntos extremos: Son los puntos potencialmente candidatos a ser la solución óptima del problema a resolver.</li> <li>Direcciones extremas: Se dan en problemas cuya región factible no es acotada, permitiendo definir el conjunto de soluciones óptimas (en caso de multiplicidad de óptimos) o la dirección de mejora cuando se obtiene solución óptima no acotada.</li> <li>Tipos de solución: Se pueden obtener diferentes conclusiones al resolver el problema.</li> </ul> <p>El método gráfico proporciona una forma clara e intuitiva de entender la optimización lineal. Comprender este método es un primer paso importante hacia herramientas de optimización más generales y potentes. Estas ideas geométricas son las que permiten generalizar el razonamiento a métodos como el Símplex, donde ya no es posible <em>dibujar</em> el problema, pero sí razonar sobre vértices y direcciones extremas.</p>]]></content><author><name></name></author><category term="algorithms"/><category term="OR"/><category term="LinearOptimization"/><category term="graphical"/><category term="resolution"/><summary type="html"><![CDATA[Resolución gráfica en optimización, herramienta conceptual previa a métodos algorítmicos como el Símplex.]]></summary></entry><entry><title type="html">Optimización lineal, matemáticas para decidir mejor</title><link href="https://fjmartincampo.github.io/spanish/blog/2026/linearoptimization/" rel="alternate" type="text/html" title="Optimización lineal, matemáticas para decidir mejor"/><published>2026-01-18T09:00:00+00:00</published><updated>2026-01-18T09:00:00+00:00</updated><id>https://fjmartincampo.github.io/blog/2026/linearoptimization</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/linearoptimization/"><![CDATA[<div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/poliedro-480.webp 480w,/assets/img/poliedro-800.webp 800w,/assets/img/poliedro-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/poliedro.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>La optimización lineal, conocida en sus orígenes como programación lineal, es la rama de las matemáticas dedicada a resolver problemas de decisión complejos cuando los recursos son limitados. Mediante modelos matemáticos simples pero poderosos, permite planificar, distribuir y asignar recursos de manera eficiente. Esta metodología tiene un impacto amplio en sectores como la logística, las finanzas y la planificación estratégica.</p> <p>La programación lineal no debe confundirse con la programación informática. En este contexto, <em>programación</em> se refiere a planificar un conjunto de acciones para resolver un problema de manera óptima, no a escribir código. Para evitar estas confusiones, en 2010 la <em>Mathematical Programming Society</em> decidió cambiar su nombre a <a href="https://www.mathopt.org"><em>Mathematical Optimization Society</em></a>, de manera que reflejara con mayor claridad su enfoque en la optimización matemática y la toma de decisiones eficiente.</p> <h2 id="desarrollo-histórico-de-la-optimización-lineal">Desarrollo histórico de la Optimización Lineal</h2> <p>La historia de la optimización lineal comienza mucho antes de que se formalizara como disciplina. Ya en 1826, <a href="https://en.wikipedia.org/wiki/Joseph_Fourier">Joseph Fourier</a> desarrolló un método matemático para eliminar variables en sistemas de inecuaciones lineales, conocido hoy como <em>Método de Eliminación de Fourier</em> <a class="citation" href="#Fourier1826">(Fourier, 1826)</a>. Su enfoque era puramente teórico, orientado a estudiar problemas de álgebra y análisis matemático. Casi un siglo después, en 1936, <a href="https://en.wikipedia.org/wiki/Theodore_Motzkin">Théodore Motzkin</a> amplió y formalizó este método para sistemas más complejos de inecuaciones, estableciendo así lo que hoy llamamos <em>Método de Eliminación de Fourier-Motzkin</em> <a class="citation" href="#Motzkin1936">(Motzkin, 1936)</a>. La diferencia fundamental entre ambos radica en que Fourier buscaba resolver problemas matemáticos generales, mientras que Motzkin sentó las bases para aplicaciones más amplias, acercándose al terreno de la optimización.</p> <p>En 1939, <a href="https://en.wikipedia.org/wiki/Theodore_Motzkin">Leonid Kantorovich</a> publicó un libro, en ruso, <a class="citation" href="#Kantorovich1939">(Kantorovich, 1939)</a> donde proponía formulaciones de optimización lineal y un método sencillo, aunque poco eficiente, para resolver problemas de asignación de recursos. Este libro se tradujo al inglés en 1960 <a class="citation" href="#Kantorovich1960">(Kantorovich, 1960)</a>. Poco después, en 1941, <a href="https://en.wikipedia.org/wiki/Frank_Lauren_Hitchcock">Frank Hitchcock</a> aplicó la optimización lineal al problema de transporte <a class="citation" href="#Hitchcock1941">(Hitchcock, 1941)</a>, mostrando cómo estas técnicas podían servir en situaciones concretas de logística.</p> <p>El gran salto ocurrió en 1947, cuando <a href="https://en.wikipedia.org/wiki/George_Dantzig">George Dantzig</a> desarrolló el <strong>Algoritmo del Símplex</strong> <a class="citation" href="#Dantzig1951">(Dantzig, 1951)</a>, un procedimiento eficiente capaz de resolver problemas de optimización lineal de manera práctica. Este algoritmo se considera piedra angular de la investigación operativa y uno de los avances más importantes del siglo XX <a class="citation" href="#Cipra2000">(Cipra, 2000)</a>. En 1951, Tjalling Koopmans utilizó la optimización lineal para formular problemas económicos complejos, demostrando su utilidad en la planificación de recursos a gran escala <a class="citation" href="#Koopmans1951">(Koopmans, 1951)</a>. Décadas más tarde, en 1984, Narendra Karmarkar presentó el <strong>Método de Punto Interior</strong> <a class="citation" href="#Karmarkar1984">(Karmarkar, 1984)</a>, mostrando que los problemas de optimización lineal podían resolverse en tiempo polinómico y no pertenecían a la clase $\mathcal{NP}$, como se pensaba anteriormente. $\mathcal{NP}$ incluye problemas cuya solución puede ser muy difícil de encontrar, mientras que $\mathcal{P}$ agrupa problemas que pueden resolverse eficientemente.</p> <p>Por sus contribuciones a la teoría de la asignación óptima de recursos, Koopmans y Kantorovich recibieron el <strong>Premio Nobel de Economía en 1975</strong>. Sin embargo, Koopmans consideró que Dantzig también merecía el premio, dado que el Algoritmo del Símplex era fundamental para la aplicación práctica de la optimización lineal y para que sus ideas pudieran implementarse en el mundo real.</p> <p>Después de ver cómo se desarrollaron los métodos que dieron forma a la optimización lineal, es útil entender los conceptos básicos que permiten formular y resolver estos problemas.</p> <h2 id="conceptos-básicos">Conceptos básicos</h2> <p>En la optimización lineal, básicamente se trata de tomar decisiones inteligentes en un entorno con recursos limitados. Para ello, se usan tres elementos clave: las <strong>variables de decisión</strong>, que representan lo que podemos controlar o ajustar; la <strong>función objetivo</strong>, que indica lo que queremos lograr, es decir, cómo maximizar ganancias o minimizar costes; y el <strong>conjunto de restricciones</strong>, que representan las limitaciones del sistema, como por ejemplo, el presupuesto, el tiempo o los materiales disponibles. Juntos, estos elementos forman un conjunto de soluciones posibles, y la tarea de la optimización lineal es encontrar la mejor opción dentro de ese conjunto. Aunque la teoría pueda sonar abstracta, estos conceptos se aplican todos los días, para decidir cuántos productos fabricar hasta planificar rutas de reparto o asignar recursos en un hospital, entre otros múltiples ejemplos.</p> <p>En optimización lineal, aunque los problemas puedan presentarse de formas muy distintas, se suelen transformar a <strong>formulación estándar</strong> o <strong>formulación canónica</strong>:</p> <ul> <li><strong>Formulación estándar</strong> <ul> <li>Todas las restricciones se expresan como <strong>igualdades</strong>.</li> <li>Todas las variables son <strong>no negativas</strong>.</li> <li>Permite que los algoritmos trabajen de forma uniforme con cualquier problema.</li> </ul> </li> </ul> \[\begin{aligned} \min\;\;\; &amp; z = \mathbf{c}^\intercal \mathbf{x} \\ \text{s.a:}\;\;\; &amp; \mathbf{A}\mathbf{x} = \mathbf{b} \\ &amp; \mathbf{x} \geqslant \mathbf{0} \end{aligned}\] <ul> <li><strong>Formulación canónica</strong> <ul> <li>Se centra en problemas de <strong>maximización</strong> (equivalentemente <strong>minimización</strong>).</li> <li>Las restricciones son del tipo <strong>≤</strong> (equivalentemente <strong>≥</strong>).</li> <li>Las variables son <strong>no negativas</strong>.</li> <li>Es la forma más habitual de presentar problemas antes de aplicar los métodos de optimización.</li> </ul> </li> </ul> \[\begin{aligned} \min\;\;\; &amp; z = \mathbf{c}^\intercal \mathbf{x} \\ \text{s.a:}\;\;\; &amp; \mathbf{A}\mathbf{x} \geqslant \mathbf{b} \\ &amp; \mathbf{x} \geqslant \mathbf{0} \end{aligned} \qquad \begin{aligned} \max\;\;\; &amp; z = \mathbf{c}^\intercal \mathbf{x} \\ \text{s.a:}\;\;\; &amp; \mathbf{A}\mathbf{x} \leqslant \mathbf{b} \\ &amp; \mathbf{x} \geqslant \mathbf{0} \end{aligned}\] <blockquote class="block-tip"> <p>Aunque estas formulaciones puedan parecer abstractas, son esenciales para convertir problemas del mundo real en <strong>modelos matemáticos resolubles por algoritmos</strong>.</p> </blockquote> <h2 id="ejemplo-ilustrativo">Ejemplo ilustrativo</h2> <p>Supongamos que una empresa produce dos productos, A y B, con los siguientes datos:</p> <ul> <li>Cada unidad de A genera 40€ de beneficio, y cada unidad de B genera 30€.</li> <li>Disponemos de 100 unidades de materia prima y 80 horas de tiempo de producción.</li> <li>Producir una unidad de A requiere 2 unidades de materia prima y 1 hora de tiempo.</li> <li>Producir una unidad de B requiere 1 unidad de materia prima y 2 horas de tiempo.</li> </ul> <p>Podemos definir las <strong>variables de decisión</strong>:</p> <ul> <li>$x_A$ = número de unidades de producto A a producir.</li> <li>$x_B$ = número de unidades de producto B a producir.</li> </ul> <p>La <strong>función objetivo</strong>, que queremos <strong>maximizar</strong>, es el beneficio total:</p> \[\max\; z = 40x_A + 30x_B\] <p>Las <strong>restricciones</strong> del sistema son:</p> <ul> <li>Materia prima disponible: \(2x_A + 1x_B \leqslant 100\)</li> <li>Tiempo disponible: \(1x_A + 2x_B \leqslant 80\)</li> <li>No se pueden producir cantidades no negativas: \(x_A \geqslant 0, \quad x_B \geqslant 0\)</li> </ul> <p>Una vez definido así, este problema puede resolverse con el Símplex o métodos de punto interior, obteniendo la combinación óptima de productos A y B.</p> <h2 id="aplicaciones-prácticas-y-utilidad">Aplicaciones prácticas y utilidad</h2> <p>La optimización lineal no es sólo un conjunto de fórmulas y algoritmos, su verdadero valor está en cómo se aplica para mejorar decisiones en la vida real. Hoy en día, esta herramienta se utiliza en <em>logística</em>, para planificar rutas de transporte y gestionar inventarios; en <em>producción industrial</em>, para asignar recursos de manera eficiente y maximizar beneficios; en <em>finanzas</em>, para diseñar carteras de inversión o presupuestos óptimos; en <em>planificación estratégica</em>, desde hospitales que gestionan camas y personal hasta empresas que optimizan la cadena de suministro. Como señalaba George Dantzig, uno de los padres fundadores de la optimización lineal, la optimización lineal permite formalizar objetivos y tomar decisiones óptimas incluso en sistemas complejos:</p> <blockquote class="block-tip"> <p>“<em>Linear programming is viewed as a revolutionary development giving man the ability to state general objectives and to find, by means of the simplex method, optimal policy decisions for a broad class of practical decision problems of great complexity. In the real world, planning tends to be ad hoc because of the many special-interest groups with their multiple objectives</em>” <a class="citation" href="#Dantzig1983">(Dantzig, 1983)</a>.</p> </blockquote> <p>Desde Fourier hasta los métodos modernos, la optimización lineal muestra cómo la teoría matemática puede generar decisiones eficientes y tangibles en el mundo real, en sectores como logística, finanzas o producción industrial.</p>]]></content><author><name></name></author><category term="history"/><category term="OR"/><category term="LinearOptimization"/><category term="definitions"/><summary type="html"><![CDATA[Un recorrido por el origen de la optimización lineal, sus conceptos básicos y su papel clave en la toma de decisiones eficientes]]></summary></entry><entry><title type="html">La ciencia detrás de la la toma de decisiones en un mundo complejo - investigación operativa</title><link href="https://fjmartincampo.github.io/spanish/blog/2026/historyOR/" rel="alternate" type="text/html" title="La ciencia detrás de la la toma de decisiones en un mundo complejo - investigación operativa"/><published>2026-01-11T15:00:00+00:00</published><updated>2026-01-11T15:00:00+00:00</updated><id>https://fjmartincampo.github.io/blog/2026/historyOR</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2026/historyOR/"><![CDATA[<div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/puzzle-480.webp 480w,/assets/img/puzzle-800.webp 800w,/assets/img/puzzle-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/puzzle.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Cada día tomamos decisiones con recursos limitados: tiempo, dinero, energía, personal o capacidad productiva, entre otros. Algunas decisiones son sencillas, pero otras afectan a sistemas grandes y complejos, en los que los distintos elementos están estrechamente interrelacionados, lo que dificulta notablemente la toma de decisiones. En estos casos, confiar únicamente en la intuición no suele ser suficiente.</p> <p>La investigación operativa surge precisamente para dar respuesta a este tipo de situaciones. Su objetivo es ayudar a tomar mejores decisiones a partir de los datos, utilizando modelos y métodos científicos, con la optimización como eje central.</p> <h2 id="evolución-histórica">Evolución histórica</h2> <p>El origen de la investigación operativa se sitúa en la Segunda Guerra Mundial. No obstante, aunque la disciplina no se formalizó hasta ese momento, su evolución puede dividirse en tres etapas: antes de la guerra, durante la guerra y después de la guerra.</p> <h3 id="cimientos-matemáticos-de-la-investigación-operativa">Cimientos matemáticos de la investigación operativa</h3> <p>La necesidad de optimizar recursos no es algo moderno. Mucho antes de que existiera la investigación operativa como disciplina, ya se planteaban problemas de este tipo:</p> <ul> <li>Encontrar las rutas más cortas y seguras para el comercio.</li> <li>Diseñar estructuras resistentes usando la menor cantidad de material.</li> <li>Maximizar beneficios o minimizar costes en actividades económicas.</li> </ul> <p>Desde el punto de vista matemático, autores como Euler, Lagrange o Gauss desarrollaron herramientas fundamentales para resolver problemas de optimización. Sin embargo, estos avances estaban más centrados en problemas teóricos y no formaban todavía una metodología aplicada de forma sistemática a la gestión de organizaciones y sistemas reales.</p> <h3 id="el-nacimiento-de-la-investigación-operativa">El nacimiento de la investigación operativa</h3> <p>La investigación operativa nace como disciplina durante la Segunda Guerra Mundial. En el Reino Unido, equipos formados por científicos de distintas áreas comenzaron a trabajar juntos para resolver problemas muy concretos:</p> <ul> <li>Cómo asignar mejor los recursos militares.</li> <li>Cómo usar el radar de forma más eficiente.</li> <li>Cómo organizar convoyes marítimos para reducir pérdidas.</li> </ul> <p>Por primera vez, la optimización se aplicaba de manera estructurada a decisiones reales de gran escala. Los resultados fueron tan positivos que, tras la guerra, este enfoque se trasladó rápidamente al ámbito civil.</p> <h3 id="de-lo-militar-a-lo-cotidiano-expansión-al-mundo-civil">De lo militar a lo cotidiano: expansión al mundo civil</h3> <p>A partir de los años 50, la investigación operativa empieza a utilizarse en empresas, administraciones públicas e industrias. Sus aplicaciones se extienden a:</p> <ul> <li>Planificación de la producción.</li> <li>Gestión de inventarios.</li> <li>Organización de turnos y personal.</li> <li>Diseño de redes de transporte y distribución.</li> </ul> <p>En esta etapa se desarrollan muchas de las herramientas clásicas de la disciplina, siempre con una pregunta de fondo: ¿cuál es la mejor forma de hacer las cosas dadas unas limitaciones?</p> <p>Para una información más detallada de la historia de la investigación operativa, ver <a class="citation" href="#historyOR">(McCloskey, 1987)</a>.</p> <h2 id="qué-es-la-investigación-operativa">¿Qué es la investigación operativa?</h2> <p>Con este contexto, resulta más sencillo comprender a qué nos referimos cuando hablamos de investigación operativa. A continuación, se presentan algunas de las definiciones formales más reconocidas:</p> <blockquote class="block-tip"> <p><strong>Operational Research Society (Reino Unido)</strong></p> <p><em>Primera definición</em>: La investigación operativa es la aplicación del método científico a problemas complejos que surgen en la dirección y gestión de grandes sistemas de personas, máquinas, materiales y dinero.</p> <p><em>Definición moderna</em>: La investigación operativa es un enfoque científico para la resolución de problemas en la gestión de sistemas complejos que permite a los responsables de la toma de decisiones tomar decisiones más acertadas.</p> </blockquote> <blockquote class="block-tip"> <p><strong>Churchman, Ackoff y Arnoff</strong> <a class="citation" href="#Churchman1957">(Churchman et al., 1957)</a></p> <p>La investigación operativa es la aplicación de métodos, técnicas y herramientas científicas a problemas que involucran el funcionamiento de un sistema, de manera que quienes controlan el sistema puedan obtener soluciones óptimas a dichos problemas.</p> </blockquote> <blockquote class="block-tip"> <p><strong>Hillier y Lieberman</strong> <a class="citation" href="#Hillier1967">(Hillier &amp; Lieberman, 1967)</a></p> <p>La investigación operativa se ocupa de determinar, mediante métodos científicos, la mejor forma de diseñar y operar sistemas hombre–máquina, generalmente en contextos que implican la asignación de recursos escasos.</p> </blockquote> <blockquote class="block-tip"> <p><strong>INFORMS</strong></p> <p>La investigación operativa y analítica es la disciplina que utiliza métodos analíticos avanzados para ayudar a tomar mejores decisiones.</p> </blockquote> <p>En términos sencillos, la investigación operativa consiste en entender un problema real, representarlo mediante un modelo abstracto y usar ese modelo para decidir mejor.</p> <h2 id="la-necesidad-de-organizar-el-conocimiento-sociedades-científicas">La necesidad de organizar el conocimiento: sociedades científicas</h2> <p>A medida que la investigación operativa crecía y se aplicaba en más ámbitos, surgió una necesidad clara: organizar a las personas que trabajaban en este campo, compartir conocimiento y dar visibilidad a la disciplina. De ahí nacen las sociedades científicas.</p> <p>Estas organizaciones permiten:</p> <ul> <li>Conectar investigadores, profesionales y estudiantes.</li> <li>Compartir avances teóricos y aplicaciones prácticas.</li> <li>Organizar congresos y encuentros científicos.</li> <li>Promover la formación y la divulgación.</li> </ul> <p>Gracias a ellas, la investigación operativa se ha consolidado como una disciplina reconocida a nivel internacional.</p> <h3 id="principales-sociedades-de-investigación-operativa">Principales sociedades de investigación operativa</h3> <ul> <li><a href="https://www.theorsociety.com">ORS</a> (Operational Research Society) – Reino Unido, 1948.</li> <li><a href="https://www.informs.org">INFORMS</a> – Estados Unidos, 1952.</li> <li><a href="https://www.ifors.org">IFORS</a> (International Federation of Operational Research Societies) – 1959.</li> <li><a href="https://www.euro-online.org">EURO</a> (Association of European Operational Research Societies) – 1975.</li> <li><a href="https://sites.google.com/view/asociacin-latino-ibero-america/">ALIO</a> (Asociación Latino-Iberoamericana de Investigación Operativa) – 1980.</li> </ul> <h3 id="la-investigación-operativa-en-españa-la-seio">La investigación operativa en España: la SEIO</h3> <p>En España, la disciplina está representada por la <a href="https://www.seio.es">SEIO</a> (Sociedad de Estadística e Investigación Operativa), que integra a investigadores y profesionales de estadística e investigación operativa.</p> <p>Sus principales objetivos son:</p> <ul> <li>Promover el desarrollo científico y aplicado de ambas disciplinas.</li> <li>Organizar congresos y actividades formativas.</li> <li>Fomentar la colaboración entre universidad, empresa y sector público.</li> <li>Difundir el papel de la investigación operativa en la sociedad.</li> </ul> <h2 id="la-investigación-operativa-en-la-actualidad">La investigación operativa en la actualidad</h2> <p>Hoy en día, la investigación operativa forma parte de muchas decisiones que afectan a nuestra vida cotidiana, aunque no siempre seamos conscientes de ello. La disciplina ha evolucionado de la mano de la informática, los datos y la creciente complejidad de los sistemas modernos. Se utiliza, por ejemplo, para:</p> <ul> <li>Logística comercial: <ul> <li>Ubicación de instalaciones.</li> <li>Gestión de almacenes.</li> <li>Planificación de la producción.</li> <li>Gestión de turnos de personal.</li> <li>Red de distribución y transporte.</li> </ul> </li> <li>Logística humanitaria: <ul> <li>Prevención: análisis de riesgo, simulación de escenarios, optimización de sistemas de alerta temprana.</li> <li>Mitigación: gestión de inventarios estratégicos y asignación de recursos.</li> <li>Preparación: planificación de rutas de evacuación, organización de personal y simulacros.</li> <li>Respuesta: distribución de ayuda humanitaria, asignación de recursos críticos y planificación bajo incertidumbre.</li> <li>Recuperación: planificación de la reconstrucción, gestión de múltiples proyectos e inventarios de largo plazo.</li> </ul> </li> <li>Logística militar: <ul> <li>Asignación óptima de recursos.</li> <li>Planificación de rutas de convoyes y transporte.</li> <li>Gestión de inventarios críticos.</li> <li>Programación de mantenimiento y reparación de equipos.</li> <li>Optimización de operaciones bajo incertidumbre.</li> </ul> </li> </ul> <p>La investigación operativa ya no se centra únicamente en encontrar soluciones “óptimas” desde un punto de vista matemático. Su objetivo actual es proporcionar decisiones útiles, robustas y aplicables, incluso cuando la información es incompleta o el problema es demasiado grande para resolverse de forma exacta.</p> <p>En un mundo cada vez más interconectado y con recursos limitados, la investigación operativa sigue siendo una herramienta esencial para entender la complejidad, evaluar alternativas y tomar mejores decisiones.</p>]]></content><author><name></name></author><category term="history"/><category term="OR"/><category term="definitions"/><category term="societies"/><summary type="html"><![CDATA[Un recorrido por la historia, las sociedades científicas y el impacto de la investigación operativa]]></summary></entry><entry><title type="html">Una formulación de optimización lineal del problema de las n-reinas</title><link href="https://fjmartincampo.github.io/spanish/blog/2025/queens/" rel="alternate" type="text/html" title="Una formulación de optimización lineal del problema de las n-reinas"/><published>2025-12-14T15:00:00+00:00</published><updated>2025-12-14T15:00:00+00:00</updated><id>https://fjmartincampo.github.io/blog/2025/queens</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2025/queens/"><![CDATA[<div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/queens-480.webp 480w,/assets/img/queens-800.webp 800w,/assets/img/queens-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/queens.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>El ajedrez es uno de los juegos de mesa más antiguos y célebres de la historia, con orígenes que se remontan a hace más de mil años. Tradicionalmente se juega sobre un tablero de $8 \times 8$ casillas y combina estrategia, táctica y pensamiento profundo, ya que cada pieza se mueve siguiendo reglas bien definidas. Más allá del propio juego, el tablero de ajedrez y sus piezas han inspirado una gran variedad de rompecabezas lógicos y retos matemáticos.</p> <p>Uno de los más conocidos es el <strong>problema de las ocho reinas</strong>, que consiste en colocar ocho reinas sobre un tablero estándar de ajedrez de manera que ninguna amenace a otra. Esto significa que no puede haber dos reinas en la misma fila, columna o diagonal. Este problema ha fascinado durante décadas a matemáticos y aficionados, ya que combina razonamiento combinatorio con una fuerte componente visual y espacial.</p> <p>El problema también puede generalizarse para tableros de otras dimensiones, $m \times n$, dando lugar a toda una familia de desafíos lógicos de complejidad creciente. Por ejemplo, el tablero que se muestra a continuación representa una posible solución al problema de las ocho reinas. En un tablero estándar de ajedrez existen en total <strong>92 soluciones distintas</strong>, lo que convierte a este rompecabezas en un ejercicio especialmente rico e interesante para quienes disfrutan de la lógica, las matemáticas y el ajedrez.</p> <div class="row justify-content-center"> <div class="col-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/queens.svg" sizes="95vw"/> <img src="/assets/img/queens.svg" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Para modelizar el problema de las reinas como un <strong>problema de optimización lineal binaria</strong>, es necesario definir primero los distintos elementos que componen el modelo.</p> <blockquote class="block-tip"> <p><em>Conjuntos de índices</em></p> <ul> <li>\(\mathcal{R}\): Filas del tablero.</li> <li>\(\mathcal{C}\): Columnas del tablero.</li> </ul> </blockquote> <blockquote class="block-tip"> <p><em>Parámetros</em></p> <ul> <li>No hay parámetros adicionales, ya que se considera que el tablero está inicialmente vacío.</li> </ul> </blockquote> <blockquote class="block-tip"> <p><em>Variables de decisión</em></p> <ul> <li>\(x_{rc}=1\) si hay una reina situada en la posición $(r,c)$ del tablero, y 0 en caso contrario.</li> </ul> </blockquote> <p>El objetivo del modelo es colocar el <strong>máximo número posible de reinas</strong> en el tablero sin que se amenacen entre sí.</p> <blockquote class="block-tip"> <p><em>Función objetivo</em></p> \[\max z = \displaystyle \sum_{r \in \mathcal{R}} \displaystyle \sum_{c \in \mathcal{C}} x_{rc}\] </blockquote> <p>A continuación, se enumeran las <strong>restricciones</strong> que garantizan que ninguna reina ataque a otra.</p> <blockquote class="block-tip"> <p><em>Cada fila puede contener como máximo una reina:</em></p> \[\displaystyle \sum_{r \in \mathcal{R}} x_{rc} \leq 1 \quad \forall c \in \mathcal{C}\] </blockquote> <blockquote class="block-tip"> <p><em>Cada columna puede contener como máximo una reina:</em></p> \[\displaystyle \sum_{c \in \mathcal{C}} x_{rc} \leq 1 \quad \forall r \in \mathcal{R}\] </blockquote> <blockquote class="block-tip"> <p><em>Cada diagonal puede contener como máximo una reina:</em></p> \[\displaystyle \sum_{(r,c):\, r-c=k} x_{rc} \leq 1 \quad \forall k = -(|\mathcal{C}|-1),\ldots,(|\mathcal{R}|-1)\] \[\displaystyle \sum_{(r,c):\, r+c=k} x_{rc} \leq 1 \quad \forall k = 2,\ldots,|\mathcal{R}|+|\mathcal{C}|\] </blockquote> <blockquote class="block-tip"> <p><em>Dominio de las variables</em></p> \[x_{rc} \in \{0,1\} \quad \forall r \in \mathcal{R}, c \in \mathcal{C}\] </blockquote> <hr/> <p><strong>Notas para el lector:</strong></p> <ul> <li>Este modelo permite resolver el problema de las $n$ reinas utilizando <strong>solvers de programación lineal binaria</strong>, como Gurobi.</li> <li>Aunque este enfoque es más matemático que la resolución manual del rompecabezas, muestra claramente cómo la <strong>modelización en optimización</strong> puede abordar de forma sistemática problemas clásicos de lógica y combinatoria.</li> </ul>]]></content><author><name></name></author><category term="modelling"/><category term="game"/><category term="chess"/><category term="n-queens"/><category term="non-attacking"/><category term="chessboard"/><summary type="html"><![CDATA[Modelización del número máximo de reinas sin atacarse en un tablero de ajedrez]]></summary></entry><entry><title type="html">Cómo resolver Sudokus con optimización lineal</title><link href="https://fjmartincampo.github.io/spanish/blog/2025/sudoku/" rel="alternate" type="text/html" title="Cómo resolver Sudokus con optimización lineal"/><published>2025-12-07T15:00:00+00:00</published><updated>2025-12-07T15:00:00+00:00</updated><id>https://fjmartincampo.github.io/blog/2025/sudoku</id><content type="html" xml:base="https://fjmartincampo.github.io/blog/2025/sudoku/"><![CDATA[<div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/sudoku-480.webp 480w,/assets/img/sudoku-800.webp 800w,/assets/img/sudoku-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/sudoku.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>El Sudoku es un juego de lógica con números que se juega en un tablero de $9 \times 9$, dividido en nueve bloques de $3 \times 3$. El objetivo consiste en rellenar el tablero con los números del $1$ al $9$ de manera que <strong>cada número aparezca una sola vez</strong> en cada fila, columna y bloque.</p> <p>La versión moderna del Sudoku se popularizó en los años 80 gracias a la empresa japonesa <strong>Nikoli</strong>, aunque su origen se remonta a un juego llamado “Number Place”, publicado en Estados Unidos en 1979. Curiosamente, “Sudoku” viene de la frase japonesa <em>“Sūji wa dokushin ni kagiru”</em>, que significa <em>“los números deben ser únicos”</em>. Desde entonces, el Sudoku se ha convertido en un fenómeno mundial, apareciendo en periódicos, libros y aplicaciones de dispositivos móviles, y es disfrutado por millones por su combinación de <strong>lógica, reconocimiento de patrones y resolución de problemas</strong>.</p> <p>Un puzzle de Sudoku empieza con algunas casillas ya rellenas. El jugador debe deducir los números restantes usando <strong>razonamiento lógico</strong>, no adivinando. Por ejemplo, mira este Sudoku:</p> <div class="row justify-content-center"> <div class="col-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/sudoku.svg" sizes="95vw"/> <img src="/assets/img/sudoku.svg" class="responsive-img" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Podría ser resuelto de este modo:</p> <div class="row justify-content-center"> <div class="col-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/sudoku2.svg" sizes="95vw"/> <img src="/assets/img/sudoku2.svg" class="responsive-img" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Para explicar cómo resolver Sudoku de forma sistemática, podemos usar un <strong>modelo de optimización lineal binaria</strong>. Primero definimos los elementos del modelo:</p> <blockquote class="block-tip"> <p><em>Conjuntos de índices</em></p> <ul> <li>\(\mathcal{R}\): Filas del tablero.</li> <li>\(\mathcal{C}\): Columnas del tablero.</li> <li>\(\mathcal{N}\): Números que usamos en el puzzle.</li> </ul> </blockquote> <blockquote class="block-tip"> <p><em>Parámetros</em></p> <ul> <li>\(A_{rc}\): Matriz con el tablero inicial (las casillas vacías se ponen iguales a 0).</li> </ul> </blockquote> <blockquote class="block-tip"> <p><em>Variables de decisión</em></p> <ul> <li>\(x_{rcn} = 1\) si el número $n$ se coloca en la fila $r$ y columna $c$, y $0$ en caso contrario.</li> </ul> </blockquote> <p>Cada puzzle de Sudoku normalmente tiene <strong>una única solución</strong>. Por eso, la función objetivo no es importante, basta con minimizar una constante ($L$):</p> <blockquote class="block-tip"> <p><em>Función objetivo</em></p> \[\min z = L\] </blockquote> <p>Ahora definimos las <strong>reglas del Sudoku</strong> como restricciones:</p> <blockquote class="block-tip"> <p><em>Cada casilla debe contener exactamente un número:</em></p> \[\displaystyle \sum_{n \in \mathcal{N}} x_{rcn} = 1 \quad \forall r \in \mathcal{R}, c \in \mathcal{C}\] </blockquote> <blockquote class="block-tip"> <p><em>Cada número aparece una vez por fila:</em></p> \[\displaystyle \sum_{r \in \mathcal{R}} x_{rcn} = 1 \quad \forall c \in \mathcal{C}, n \in \mathcal{N}\] </blockquote> <blockquote class="block-tip"> <p><em>Cada número aparece una vez por columna:</em></p> \[\displaystyle \sum_{c \in \mathcal{C}} x_{rcn} = 1 \quad \forall r \in \mathcal{R}, n \in \mathcal{N}\] </blockquote> <blockquote class="block-tip"> <p><em>Cada número aparece una vez por bloque $3 \times 3$:</em></p> \[\displaystyle \sum_{r=3p-2}^{3p} \sum_{c=3q-2}^{3q} x_{rcn} = 1 \quad \forall n \in \mathcal{N}, \; p,q \in \{1,2,3\}\] </blockquote> <p>Por último, definimos <strong>el dominio de las variables</strong>:</p> <blockquote class="block-tip"> <p><em>Dominio de las variables</em></p> \[x_{rcn} \in \{0,1\} \quad \forall r \in \mathcal{R}, c \in \mathcal{C}, n \in \mathcal{N}\] </blockquote> <hr/> <p><strong>Notas para el lector:</strong></p> <ul> <li>Con esta formulación, podemos resolver un Sudoku usando optimizadores de <strong>programación lineal binaria</strong> como Gurobi.</li> <li>Aunque es más matemático que los métodos tradicionales, este enfoque muestra cómo el <strong>modelado de optimización</strong> puede ayudarnos a resolver problemas de lógica de manera sistemática.</li> </ul>]]></content><author><name></name></author><category term="modelling"/><category term="game"/><category term="sudoku"/><summary type="html"><![CDATA[Modelización de un sudoku]]></summary></entry></feed>